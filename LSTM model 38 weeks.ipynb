{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6383c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import shap #Check version, SHAP 0.36.0\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, InputLayer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from yellowbrick.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f14e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb1eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.read_csv(r\"C:/Users/Nicklas Branding/Desktop/infection_per_sweden_on_covid19.csv\",encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63c5269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>år</th>\n",
       "      <th>veckonummer</th>\n",
       "      <th>Antal_fall_vecka</th>\n",
       "      <th>Antal_fall_100000inv_vecka</th>\n",
       "      <th>Antal_fall_100000inv_14dagar</th>\n",
       "      <th>Kum_antal_fall</th>\n",
       "      <th>Kum_fall_100000inv</th>\n",
       "      <th>Antal_nyaintensivvårdade_vecka</th>\n",
       "      <th>Kum_antal_intensivvårdade</th>\n",
       "      <th>Antal_avlidna_vecka</th>\n",
       "      <th>Antal_avlidna_milj_inv_vecka</th>\n",
       "      <th>Kum_antal_avlidna</th>\n",
       "      <th>Kum_antal_avlidna_milj_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     år  veckonummer  Antal_fall_vecka  Antal_fall_100000inv_vecka  \\\n",
       "0  2020            6                 1                           0   \n",
       "1  2020            7                 0                           0   \n",
       "2  2020            8                 0                           0   \n",
       "3  2020            9                13                           0   \n",
       "4  2020           10               211                           2   \n",
       "\n",
       "   Antal_fall_100000inv_14dagar  Kum_antal_fall  Kum_fall_100000inv  \\\n",
       "0                             0               1                   0   \n",
       "1                             0               1                   0   \n",
       "2                             0               1                   0   \n",
       "3                             0              14                   0   \n",
       "4                             2             225                   2   \n",
       "\n",
       "   Antal_nyaintensivvårdade_vecka  Kum_antal_intensivvårdade  \\\n",
       "0                               0                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               3                          3   \n",
       "\n",
       "   Antal_avlidna_vecka  Antal_avlidna_milj_inv_vecka  Kum_antal_avlidna  \\\n",
       "0                    0                             0                  0   \n",
       "1                    0                             0                  0   \n",
       "2                    0                             0                  0   \n",
       "3                    0                             0                  0   \n",
       "4                    0                             0                  0   \n",
       "\n",
       "   Kum_antal_avlidna_milj_inv  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b708be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = df_predict.drop(['Antal_fall_100000inv_vecka', 'Antal_fall_100000inv_14dagar', 'Kum_antal_fall', 'Kum_fall_100000inv', 'Antal_nyaintensivvårdade_vecka', 'Kum_antal_intensivvårdade', 'Antal_avlidna_vecka', 'Antal_avlidna_milj_inv_vecka', 'Kum_antal_avlidna', 'Kum_antal_avlidna_milj_inv','veckonummer','år'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe9a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['Antal_fall_vecka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af457dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX_predict = df_predict[feature]\n",
    "#dfX.head(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce54b461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac47ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = df_predict.mean(0)\n",
    "sd = df_predict.std(0)\n",
    "df_norm = (df_predict - mu) / sd\n",
    "df_norm.head(3)\n",
    "Y_mu_2 = np.asarray(mu[feature])\n",
    "Y_sd_2 = np.asarray(sd[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55523973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.80600237],\n",
       "       [-0.80605767],\n",
       "       [-0.80605767],\n",
       "       [-0.80533875],\n",
       "       [-0.79438912],\n",
       "       [-0.7597153 ],\n",
       "       [-0.7549594 ],\n",
       "       [-0.6978333 ],\n",
       "       [-0.62749022],\n",
       "       [-0.59923133],\n",
       "       [-0.59856771],\n",
       "       [-0.57362689],\n",
       "       [-0.59414362],\n",
       "       [-0.57639195],\n",
       "       [-0.59209748],\n",
       "       [-0.60371072],\n",
       "       [-0.5693687 ],\n",
       "       [-0.47308938],\n",
       "       [-0.4121475 ],\n",
       "       [-0.41491256],\n",
       "       [-0.39378752],\n",
       "       [-0.569424  ],\n",
       "       [-0.68555644],\n",
       "       [-0.71635919],\n",
       "       [-0.73328134],\n",
       "       [-0.72000906],\n",
       "       [-0.69468113],\n",
       "       [-0.69257969],\n",
       "       [-0.71276461],\n",
       "       [-0.73969628],\n",
       "       [-0.73239652],\n",
       "       [-0.71801822],\n",
       "       [-0.69103125],\n",
       "       [-0.64463358],\n",
       "       [-0.60465084],\n",
       "       [-0.5694793 ],\n",
       "       [-0.49526515],\n",
       "       [-0.29977554],\n",
       "       [ 0.21557597],\n",
       "       [ 0.59886831],\n",
       "       [ 0.92591937],\n",
       "       [ 0.9604826 ],\n",
       "       [ 1.1604516 ],\n",
       "       [ 1.23107118],\n",
       "       [ 1.60678726],\n",
       "       [ 1.74758402],\n",
       "       [ 1.24749562],\n",
       "       [ 1.47915218],\n",
       "       [ 1.37557311],\n",
       "       [ 0.79424731],\n",
       "       [ 0.47836708],\n",
       "       [ 0.3362431 ],\n",
       "       [ 0.27812158],\n",
       "       [ 0.37091693],\n",
       "       [ 0.49987923],\n",
       "       [ 0.669875  ],\n",
       "       [ 0.72816243],\n",
       "       [ 0.77312227],\n",
       "       [ 1.02065026],\n",
       "       [ 1.28875029],\n",
       "       [ 1.31673268],\n",
       "       [ 1.46925328],\n",
       "       [ 1.46322545],\n",
       "       [ 1.18655374],\n",
       "       [ 1.1464051 ],\n",
       "       [ 1.05648541],\n",
       "       [ 0.6270166 ],\n",
       "       [ 0.19870912],\n",
       "       [-0.36508622],\n",
       "       [-0.30314892],\n",
       "       [-0.56306437],\n",
       "       [-0.64855996],\n",
       "       [-0.69639547],\n",
       "       [-0.7026445 ],\n",
       "       [-0.72233171],\n",
       "       [-0.70192558],\n",
       "       [-0.65884598],\n",
       "       [-0.61471565],\n",
       "       [-0.55122992],\n",
       "       [-0.48426022],\n",
       "       [-0.44864627],\n",
       "       [-0.43620351],\n",
       "       [-0.40578787],\n",
       "       [-0.36536272],\n",
       "       [-0.4598171 ],\n",
       "       [-0.56809678],\n",
       "       [-0.57202316],\n",
       "       [-0.57722147],\n",
       "       [-0.58109255],\n",
       "       [-0.51887874],\n",
       "       [-0.47917251],\n",
       "       [-0.5262338 ],\n",
       "       [-0.48420491],\n",
       "       [-0.41375124],\n",
       "       [-0.14719964],\n",
       "       [-0.04290165],\n",
       "       [ 0.22530897],\n",
       "       [ 0.5508669 ],\n",
       "       [ 0.74491868],\n",
       "       [ 2.48159632],\n",
       "       [ 6.06295477]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = np.asarray(df_norm)\n",
    "df_norm.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9a6cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df_norm[0:61]\n",
    "testing_data_39 = df_norm[61:101]\n",
    "testing_data_31 = df_norm[61:93]\n",
    "testing_data_15 = df_norm[61:77]\n",
    "testing_data_7 = df_norm[61:69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfffefce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples 59\n"
     ]
    }
   ],
   "source": [
    "look_back=2\n",
    "train_genertor = TimeseriesGenerator(training_data,training_data,length=look_back,batch_size=1)\n",
    "test_genertor_39 = TimeseriesGenerator(testing_data_39,testing_data_39,length=look_back,batch_size=1)\n",
    "test_genertor_31 = TimeseriesGenerator(testing_data_31,testing_data_31,length=look_back,batch_size=1)\n",
    "test_genertor_15 = TimeseriesGenerator(testing_data_15,testing_data_15,length=look_back,batch_size=1)\n",
    "test_genertor_7 = TimeseriesGenerator(testing_data_7,testing_data_7,length=look_back,batch_size=1)\n",
    "print(\"samples\", len(train_genertor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23f2b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_1_sample = test_genertor_39[0]\n",
    "Y_test_1_sample = testing_data_39[0:1]\n",
    "\n",
    "X_test_2_sample = test_genertor_39[1]\n",
    "Y_test_2_sample = testing_data_39[1:2]\n",
    "\n",
    "X_test_3_sample = test_genertor_39[2]\n",
    "Y_test_3_sample = testing_data_39[2:3]\n",
    "\n",
    "X_test_4_sample = test_genertor_39[3]\n",
    "Y_test_4_sample = testing_data_39[3:4]\n",
    "\n",
    "X_test_5_sample = test_genertor_39[4]\n",
    "Y_test_5_sample = testing_data_39[4:5]\n",
    "\n",
    "X_test_6_sample = test_genertor_39[5]\n",
    "Y_test_6_sample = testing_data_39[5:6]\n",
    "\n",
    "X_test_7_sample = test_genertor_39[6]\n",
    "Y_test_7_sample = testing_data_39[6:7]\n",
    "\n",
    "X_test_8_sample = test_genertor_39[7]\n",
    "Y_test_8_sample = testing_data_39[7:8]\n",
    "\n",
    "X_test_9_sample = test_genertor_39[8]\n",
    "Y_test_9_sample = testing_data_39[8:9]\n",
    "\n",
    "X_test_10_sample = test_genertor_39[9]\n",
    "Y_test_10_sample = testing_data_39[9:10]\n",
    "\n",
    "X_test_11_sample = test_genertor_39[10]\n",
    "Y_test_11_sample = testing_data_39[10:11]\n",
    "\n",
    "X_test_12_sample = test_genertor_39[11]\n",
    "Y_test_12_sample = testing_data_39[11:12]\n",
    "\n",
    "X_test_13_sample = test_genertor_39[12]\n",
    "Y_test_13_sample = testing_data_39[12:13]\n",
    "\n",
    "X_test_14_sample = test_genertor_39[13]\n",
    "Y_test_14_sample = testing_data_39[13:14]\n",
    "\n",
    "X_test_15_sample = test_genertor_39[14]\n",
    "Y_test_15_sample = testing_data_39[14:15]\n",
    "\n",
    "X_test_16_sample = test_genertor_39[15]\n",
    "Y_test_16_sample = testing_data_39[15:16]\n",
    "\n",
    "X_test_17_sample = test_genertor_39[16]\n",
    "Y_test_17_sample = testing_data_39[16:17]\n",
    "\n",
    "X_test_18_sample = test_genertor_39[17]\n",
    "Y_test_18_sample = testing_data_39[17:18]\n",
    "\n",
    "X_test_19_sample = test_genertor_39[18]\n",
    "Y_test_19_sample = testing_data_39[18:19]\n",
    "\n",
    "X_test_20_sample = test_genertor_39[19]\n",
    "Y_test_20_sample = testing_data_39[19:20]\n",
    "\n",
    "X_test_21_sample = test_genertor_39[20]\n",
    "Y_test_21_sample = testing_data_39[20:21]\n",
    "\n",
    "X_test_22_sample = test_genertor_39[21]\n",
    "Y_test_22_sample = testing_data_39[21:22]\n",
    "\n",
    "X_test_23_sample = test_genertor_39[22]\n",
    "Y_test_23_sample = testing_data_39[22:23]\n",
    "\n",
    "X_test_24_sample = test_genertor_39[23]\n",
    "Y_test_24_sample = testing_data_39[23:24]\n",
    "\n",
    "X_test_25_sample = test_genertor_39[24]\n",
    "Y_test_25_sample = testing_data_39[24:25]\n",
    "\n",
    "X_test_26_sample = test_genertor_39[25]\n",
    "Y_test_26_sample = testing_data_39[25:26]\n",
    "\n",
    "X_test_27_sample = test_genertor_39[26]\n",
    "Y_test_27_sample = testing_data_39[26:27]\n",
    "\n",
    "X_test_28_sample = test_genertor_39[27]\n",
    "Y_test_28_sample = testing_data_39[27:28]\n",
    "\n",
    "X_test_29_sample = test_genertor_39[28]\n",
    "Y_test_29_sample = testing_data_39[28:29]\n",
    "\n",
    "X_test_30_sample = test_genertor_39[29]\n",
    "Y_test_30_sample = testing_data_39[29:30]\n",
    "\n",
    "X_test_31_sample = test_genertor_39[30]\n",
    "Y_test_31_sample = testing_data_39[30:31]\n",
    "\n",
    "X_test_32_sample = test_genertor_39[31]\n",
    "Y_test_32_sample = testing_data_39[31:32]\n",
    "\n",
    "X_test_33_sample = test_genertor_39[32]\n",
    "Y_test_33_sample = testing_data_39[32:33]\n",
    "\n",
    "X_test_34_sample = test_genertor_39[33]\n",
    "Y_test_34_sample = testing_data_39[33:34]\n",
    "\n",
    "X_test_35_sample = test_genertor_39[34]\n",
    "Y_test_35_sample = testing_data_39[34:35]\n",
    "\n",
    "X_test_36_sample = test_genertor_39[35]\n",
    "Y_test_36_sample = testing_data_39[35:36]\n",
    "\n",
    "X_test_37_sample = test_genertor_39[36]\n",
    "Y_test_37_sample = testing_data_39[36:37]\n",
    "\n",
    "X_test_38_sample = test_genertor_39[37]\n",
    "Y_test_38_sample = testing_data_39[37:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b571c67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1300\n",
      "1/1 [==============================] - 5s 5s/step - loss: 3.0528 - val_loss: 0.3936\n",
      "Epoch 2/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1373 - val_loss: 0.3936\n",
      "Epoch 3/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6316 - val_loss: 0.3935\n",
      "Epoch 4/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3293 - val_loss: 0.3933\n",
      "Epoch 5/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4474 - val_loss: 0.3932\n",
      "Epoch 6/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6572 - val_loss: 0.3932\n",
      "Epoch 7/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7289 - val_loss: 0.3931\n",
      "Epoch 8/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3243 - val_loss: 0.3931\n",
      "Epoch 9/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4155 - val_loss: 0.3929\n",
      "Epoch 10/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4824 - val_loss: 0.3928\n",
      "Epoch 11/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1698 - val_loss: 0.3927\n",
      "Epoch 12/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1783 - val_loss: 0.3926\n",
      "Epoch 13/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2235 - val_loss: 0.3925\n",
      "Epoch 14/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3640 - val_loss: 0.3924\n",
      "Epoch 15/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4696 - val_loss: 0.3922\n",
      "Epoch 16/1300\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5685 - val_loss: 0.3921\n",
      "Epoch 17/1300\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.5270 - val_loss: 0.3920\n",
      "Epoch 18/1300\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.5117 - val_loss: 0.3918\n",
      "Epoch 19/1300\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8542 - val_loss: 0.3917\n",
      "Epoch 20/1300\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1714 - val_loss: 0.3916\n",
      "Epoch 21/1300\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2439 - val_loss: 0.3915\n",
      "Epoch 22/1300\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.7250 - val_loss: 0.3914\n",
      "Epoch 23/1300\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5128 - val_loss: 0.3913\n",
      "Epoch 24/1300\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1362 - val_loss: 0.3912\n",
      "Epoch 25/1300\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.7243 - val_loss: 0.3911\n",
      "Epoch 26/1300\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.8537 - val_loss: 0.3911\n",
      "Epoch 27/1300\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5263 - val_loss: 0.3910\n",
      "Epoch 28/1300\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5260 - val_loss: 0.3910\n",
      "Epoch 29/1300\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.9160 - val_loss: 0.3910\n",
      "Epoch 30/1300\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1357 - val_loss: 0.3910\n",
      "Epoch 31/1300\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.5053 - val_loss: 0.3910\n",
      "Epoch 32/1300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.2470 - val_loss: 0.3910\n",
      "Epoch 33/1300\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.9146 - val_loss: 0.3910\n",
      "Epoch 34/1300\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.6212 - val_loss: 0.3911\n",
      "Epoch 35/1300\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 1.5394 - val_loss: 0.3911\n",
      "Epoch 36/1300\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.6464 - val_loss: 0.3911\n",
      "Epoch 37/1300\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.5741 - val_loss: 0.3910\n",
      "Epoch 38/1300\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1347 - val_loss: 0.3910\n",
      "Epoch 39/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5005 - val_loss: 0.3910\n",
      "Epoch 40/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0467 - val_loss: 0.3910\n",
      "Epoch 41/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4751 - val_loss: 0.3910\n",
      "Epoch 42/1300\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2220 - val_loss: 0.3909\n",
      "Epoch 43/1300\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.3493 - val_loss: 0.3909\n",
      "Epoch 44/1300\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.3227 - val_loss: 0.3908\n",
      "Epoch 45/1300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4420 - val_loss: 0.3907\n",
      "Epoch 46/1300\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2452 - val_loss: 0.3906\n",
      "Epoch 47/1300\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2225 - val_loss: 0.3906\n",
      "Epoch 48/1300\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5665 - val_loss: 0.3905\n",
      "Epoch 49/1300\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1547 - val_loss: 0.3903\n",
      "Epoch 50/1300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3566 - val_loss: 0.3902\n",
      "Epoch 51/1300\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.5326 - val_loss: 0.3901\n",
      "Epoch 52/1300\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2450 - val_loss: 0.3900\n",
      "Epoch 53/1300\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.4122 - val_loss: 0.3899\n",
      "Epoch 54/1300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.4965 - val_loss: 0.3898\n",
      "Epoch 55/1300\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.3559 - val_loss: 0.3897\n",
      "Epoch 56/1300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9095 - val_loss: 0.3896\n",
      "Epoch 57/1300\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.5111 - val_loss: 0.3895\n",
      "Epoch 58/1300\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2215 - val_loss: 0.3893\n",
      "Epoch 59/1300\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.3227 - val_loss: 0.3892\n",
      "Epoch 60/1300\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.3498 - val_loss: 0.3890\n",
      "Epoch 61/1300\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.5711 - val_loss: 0.3888\n",
      "Epoch 62/1300\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.3493 - val_loss: 0.3886\n",
      "Epoch 63/1300\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.5871 - val_loss: 0.3885\n",
      "Epoch 64/1300\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.5094 - val_loss: 0.3883\n",
      "Epoch 65/1300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6418 - val_loss: 0.3881\n",
      "Epoch 66/1300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2414 - val_loss: 0.3879\n",
      "Epoch 67/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3535 - val_loss: 0.3877\n",
      "Epoch 68/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5874 - val_loss: 0.3876\n",
      "Epoch 69/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2195 - val_loss: 0.3874\n",
      "Epoch 70/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3523 - val_loss: 0.3872\n",
      "Epoch 71/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7115 - val_loss: 0.3870\n",
      "Epoch 72/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4742 - val_loss: 0.3869\n",
      "Epoch 73/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1685 - val_loss: 0.3867\n",
      "Epoch 74/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0277 - val_loss: 0.3866\n",
      "Epoch 75/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5377 - val_loss: 0.3864\n",
      "Epoch 76/1300\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0274 - val_loss: 0.3863\n",
      "Epoch 77/1300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6192 - val_loss: 0.3861\n",
      "Epoch 78/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6410 - val_loss: 0.3860\n",
      "Epoch 79/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4064 - val_loss: 0.3858\n",
      "Epoch 80/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3571 - val_loss: 0.3857\n",
      "Epoch 81/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1341 - val_loss: 0.3855\n",
      "Epoch 82/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5361 - val_loss: 0.3854\n",
      "Epoch 83/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3163 - val_loss: 0.3852\n",
      "Epoch 84/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5038 - val_loss: 0.3850\n",
      "Epoch 85/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5242 - val_loss: 0.3848\n",
      "Epoch 86/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5238 - val_loss: 0.3846\n",
      "Epoch 87/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.0167 - val_loss: 0.3844\n",
      "Epoch 88/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2192 - val_loss: 0.3842\n",
      "Epoch 89/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5337 - val_loss: 0.3840\n",
      "Epoch 90/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5248 - val_loss: 0.3838\n",
      "Epoch 91/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.8616 - val_loss: 0.3837\n",
      "Epoch 92/1300\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3250 - val_loss: 0.3835\n",
      "Epoch 93/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6313 - val_loss: 0.3834\n",
      "Epoch 94/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4027 - val_loss: 0.3832\n",
      "Epoch 95/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3136 - val_loss: 0.3830\n",
      "Epoch 96/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3535 - val_loss: 0.3828\n",
      "Epoch 97/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6312 - val_loss: 0.3826\n",
      "Epoch 98/1300\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.4889 - val_loss: 0.3824\n",
      "Epoch 99/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5521 - val_loss: 0.3821\n",
      "Epoch 100/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3523 - val_loss: 0.3819\n",
      "Epoch 101/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5581 - val_loss: 0.3816\n",
      "Epoch 102/1300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5011 - val_loss: 0.3813\n",
      "Epoch 103/1300\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.3216 - val_loss: 0.3811\n",
      "Epoch 104/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5190 - val_loss: 0.3809\n",
      "Epoch 105/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1068 - val_loss: 0.3807\n",
      "Epoch 106/1300\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5491 - val_loss: 0.3805\n",
      "Epoch 107/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3438 - val_loss: 0.3802\n",
      "Epoch 108/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3186 - val_loss: 0.3800\n",
      "Epoch 109/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3432 - val_loss: 0.3797\n",
      "Epoch 110/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3428 - val_loss: 0.3794\n",
      "Epoch 111/1300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3142 - val_loss: 0.3791\n",
      "Epoch 112/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4617 - val_loss: 0.3788\n",
      "Epoch 113/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5185 - val_loss: 0.3786\n",
      "Epoch 114/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3412 - val_loss: 0.3783\n",
      "Epoch 115/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5388 - val_loss: 0.3780\n",
      "Epoch 116/1300\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6206 - val_loss: 0.3778\n",
      "Epoch 117/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5140 - val_loss: 0.3775\n",
      "Epoch 118/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4527 - val_loss: 0.3772\n",
      "Epoch 119/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3457 - val_loss: 0.3769\n",
      "Epoch 120/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5489 - val_loss: 0.3766\n",
      "Epoch 121/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1062 - val_loss: 0.3763\n",
      "Epoch 122/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4398 - val_loss: 0.3761\n",
      "Epoch 123/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5203 - val_loss: 0.3758\n",
      "Epoch 124/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4563 - val_loss: 0.3755\n",
      "Epoch 125/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2447 - val_loss: 0.3752\n",
      "Epoch 126/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.6301 - val_loss: 0.3750\n",
      "Epoch 127/1300\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.4819 - val_loss: 0.3748\n",
      "Epoch 128/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4897 - val_loss: 0.3745\n",
      "Epoch 129/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3074 - val_loss: 0.3743\n",
      "Epoch 130/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.8461 - val_loss: 0.3741\n",
      "Epoch 131/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4573 - val_loss: 0.3738\n",
      "Epoch 132/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5157 - val_loss: 0.3736\n",
      "Epoch 133/1300\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4565 - val_loss: 0.3733\n",
      "Epoch 134/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6011 - val_loss: 0.3731\n",
      "Epoch 135/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3021 - val_loss: 0.3728\n",
      "Epoch 136/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4847 - val_loss: 0.3725\n",
      "Epoch 137/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.8420 - val_loss: 0.3722\n",
      "Epoch 138/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2121 - val_loss: 0.3720\n",
      "Epoch 139/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.3108 - val_loss: 0.3717\n",
      "Epoch 140/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3051 - val_loss: 0.3715\n",
      "Epoch 141/1300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3326 - val_loss: 0.3712\n",
      "Epoch 142/1300\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4469 - val_loss: 0.3708\n",
      "Epoch 143/1300\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.3274 - val_loss: 0.3705\n",
      "Epoch 144/1300\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8423 - val_loss: 0.3702\n",
      "Epoch 145/1300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.8359 - val_loss: 0.3699\n",
      "Epoch 146/1300\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.3241 - val_loss: 0.3696\n",
      "Epoch 147/1300\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.3373 - val_loss: 0.3692\n",
      "Epoch 148/1300\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.3060 - val_loss: 0.3688\n",
      "Epoch 149/1300\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.5088 - val_loss: 0.3684\n",
      "Epoch 150/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3289 - val_loss: 0.3680\n",
      "Epoch 151/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3218 - val_loss: 0.3675\n",
      "Epoch 152/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0709 - val_loss: 0.3671\n",
      "Epoch 153/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3325 - val_loss: 0.3667\n",
      "Epoch 154/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6813 - val_loss: 0.3663\n",
      "Epoch 155/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2942 - val_loss: 0.3658\n",
      "Epoch 156/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4924 - val_loss: 0.3653\n",
      "Epoch 157/1300\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.1376 - val_loss: 0.3649\n",
      "Epoch 158/1300\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.0082 - val_loss: 0.3645\n",
      "Epoch 159/1300\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4722 - val_loss: 0.3640\n",
      "Epoch 160/1300\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.3230 - val_loss: 0.3635\n",
      "Epoch 161/1300\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.4994 - val_loss: 0.3630\n",
      "Epoch 162/1300\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0731 - val_loss: 0.3624\n",
      "Epoch 163/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step - loss: 0.2956 - val_loss: 0.3619\n",
      "Epoch 164/1300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.1078 - val_loss: 0.3614\n",
      "Epoch 165/1300\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2414 - val_loss: 0.3609\n",
      "Epoch 166/1300\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.3261 - val_loss: 0.3605\n",
      "Epoch 167/1300\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0598 - val_loss: 0.3600\n",
      "Epoch 168/1300\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.4638 - val_loss: 0.3597\n",
      "Epoch 169/1300\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.4282 - val_loss: 0.3592\n",
      "Epoch 170/1300\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.3802 - val_loss: 0.3589\n",
      "Epoch 171/1300\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.3125 - val_loss: 0.3586\n",
      "Epoch 172/1300\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.4314 - val_loss: 0.3581\n",
      "Epoch 173/1300\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4584 - val_loss: 0.3576\n",
      "Epoch 174/1300\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.422 - 0s 163ms/step - loss: 0.4221 - val_loss: 0.3571\n",
      "Epoch 175/1300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.8198 - val_loss: 0.3565\n",
      "Epoch 176/1300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3094 - val_loss: 0.3560\n",
      "Epoch 177/1300\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.2898 - val_loss: 0.3554\n",
      "Epoch 178/1300\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.6702 - val_loss: 0.3548\n",
      "Epoch 179/1300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2043 - val_loss: 0.3543\n",
      "Epoch 180/1300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1299 - val_loss: 0.3539\n",
      "Epoch 181/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4564 - val_loss: 0.3535\n",
      "Epoch 182/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8855 - val_loss: 0.3532\n",
      "Epoch 183/1300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.4550 - val_loss: 0.3527\n",
      "Epoch 184/1300\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6023 - val_loss: 0.3523\n",
      "Epoch 185/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2761 - val_loss: 0.3519\n",
      "Epoch 186/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2772 - val_loss: 0.3514\n",
      "Epoch 187/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4213 - val_loss: 0.3508\n",
      "Epoch 188/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2760 - val_loss: 0.3502\n",
      "Epoch 189/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8807 - val_loss: 0.3496\n",
      "Epoch 190/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4977 - val_loss: 0.3490\n",
      "Epoch 191/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0650 - val_loss: 0.3484\n",
      "Epoch 192/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4615 - val_loss: 0.3479\n",
      "Epoch 193/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0655 - val_loss: 0.3475\n",
      "Epoch 194/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0674 - val_loss: 0.3471\n",
      "Epoch 195/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4402 - val_loss: 0.3466\n",
      "Epoch 196/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4394 - val_loss: 0.3461\n",
      "Epoch 197/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4085 - val_loss: 0.3454\n",
      "Epoch 198/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1329 - val_loss: 0.3447\n",
      "Epoch 199/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8756 - val_loss: 0.3441\n",
      "Epoch 200/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3450 - val_loss: 0.3434\n",
      "Epoch 201/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8319 - val_loss: 0.3428\n",
      "Epoch 202/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.2778 - val_loss: 0.3423\n",
      "Epoch 203/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4976 - val_loss: 0.3418\n",
      "Epoch 204/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4384 - val_loss: 0.3413\n",
      "Epoch 205/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5478 - val_loss: 0.3406\n",
      "Epoch 206/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9853 - val_loss: 0.3399\n",
      "Epoch 207/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8709 - val_loss: 0.3393\n",
      "Epoch 208/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3973 - val_loss: 0.3386\n",
      "Epoch 209/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4337 - val_loss: 0.3379\n",
      "Epoch 210/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3934 - val_loss: 0.3370\n",
      "Epoch 211/1300\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4301 - val_loss: 0.3362\n",
      "Epoch 212/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4531 - val_loss: 0.3353\n",
      "Epoch 213/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4285 - val_loss: 0.3343\n",
      "Epoch 214/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4179 - val_loss: 0.3333\n",
      "Epoch 215/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5523 - val_loss: 0.3323\n",
      "Epoch 216/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4461 - val_loss: 0.3313\n",
      "Epoch 217/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3852 - val_loss: 0.3302\n",
      "Epoch 218/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1906 - val_loss: 0.3292\n",
      "Epoch 219/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6309 - val_loss: 0.3282\n",
      "Epoch 220/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2994 - val_loss: 0.3272\n",
      "Epoch 221/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4154 - val_loss: 0.3260\n",
      "Epoch 222/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0770 - val_loss: 0.3251\n",
      "Epoch 223/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7670 - val_loss: 0.3242\n",
      "Epoch 224/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6251 - val_loss: 0.3234\n",
      "Epoch 225/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5475 - val_loss: 0.3226\n",
      "Epoch 226/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2702 - val_loss: 0.3217\n",
      "Epoch 227/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4074 - val_loss: 0.3211\n",
      "Epoch 228/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3679 - val_loss: 0.3204\n",
      "Epoch 229/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2555 - val_loss: 0.3195\n",
      "Epoch 230/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5466 - val_loss: 0.3187\n",
      "Epoch 231/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2855 - val_loss: 0.3178\n",
      "Epoch 232/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2486 - val_loss: 0.3170\n",
      "Epoch 233/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1111 - val_loss: 0.3161\n",
      "Epoch 234/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4323 - val_loss: 0.3151\n",
      "Epoch 235/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0885 - val_loss: 0.3141\n",
      "Epoch 236/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2688 - val_loss: 0.3130\n",
      "Epoch 237/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5391 - val_loss: 0.3121\n",
      "Epoch 238/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1148 - val_loss: 0.3111\n",
      "Epoch 239/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1140 - val_loss: 0.3101\n",
      "Epoch 240/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2511 - val_loss: 0.3090\n",
      "Epoch 241/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1445 - val_loss: 0.3078\n",
      "Epoch 242/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2608 - val_loss: 0.3066\n",
      "Epoch 243/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1031 - val_loss: 0.3054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4204 - val_loss: 0.3045\n",
      "Epoch 245/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0865 - val_loss: 0.3036\n",
      "Epoch 246/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1562 - val_loss: 0.3027\n",
      "Epoch 247/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2154 - val_loss: 0.3017\n",
      "Epoch 248/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2280 - val_loss: 0.3008\n",
      "Epoch 249/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2364 - val_loss: 0.2998\n",
      "Epoch 250/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3298 - val_loss: 0.2986\n",
      "Epoch 251/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2174 - val_loss: 0.2973\n",
      "Epoch 252/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3762 - val_loss: 0.2959\n",
      "Epoch 253/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2351 - val_loss: 0.2944\n",
      "Epoch 254/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3636 - val_loss: 0.2928\n",
      "Epoch 255/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3745 - val_loss: 0.2911\n",
      "Epoch 256/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2271 - val_loss: 0.2894\n",
      "Epoch 257/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0856 - val_loss: 0.2877\n",
      "Epoch 258/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2214 - val_loss: 0.2861\n",
      "Epoch 259/1300\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.300 - 0s 87ms/step - loss: 0.3001 - val_loss: 0.2843\n",
      "Epoch 260/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2164 - val_loss: 0.2824\n",
      "Epoch 261/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.9768 - val_loss: 0.2806\n",
      "Epoch 262/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5389 - val_loss: 0.2790\n",
      "Epoch 263/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0807 - val_loss: 0.2773\n",
      "Epoch 264/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4093 - val_loss: 0.2758\n",
      "Epoch 265/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2306 - val_loss: 0.2746\n",
      "Epoch 266/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1908 - val_loss: 0.2732\n",
      "Epoch 267/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3043 - val_loss: 0.2716\n",
      "Epoch 268/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.3809 - val_loss: 0.2700\n",
      "Epoch 269/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1990 - val_loss: 0.2684\n",
      "Epoch 270/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1888 - val_loss: 0.2666\n",
      "Epoch 271/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.7008 - val_loss: 0.2649\n",
      "Epoch 272/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0818 - val_loss: 0.2634\n",
      "Epoch 273/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0690 - val_loss: 0.2618\n",
      "Epoch 274/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4685 - val_loss: 0.2604\n",
      "Epoch 275/1300\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2809 - val_loss: 0.2587\n",
      "Epoch 276/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4664 - val_loss: 0.2572\n",
      "Epoch 277/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2942 - val_loss: 0.2555\n",
      "Epoch 278/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3553 - val_loss: 0.2538\n",
      "Epoch 279/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1610 - val_loss: 0.2520\n",
      "Epoch 280/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.9274 - val_loss: 0.2504\n",
      "Epoch 281/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1775 - val_loss: 0.2485\n",
      "Epoch 282/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1714 - val_loss: 0.2466\n",
      "Epoch 283/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2354 - val_loss: 0.2444\n",
      "Epoch 284/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2512 - val_loss: 0.2421\n",
      "Epoch 285/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4899 - val_loss: 0.2398\n",
      "Epoch 286/1300\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1495 - val_loss: 0.2376\n",
      "Epoch 287/1300\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4554 - val_loss: 0.2355\n",
      "Epoch 288/1300\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2339 - val_loss: 0.2332\n",
      "Epoch 289/1300\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.2943 - val_loss: 0.2309\n",
      "Epoch 290/1300\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1470 - val_loss: 0.2286\n",
      "Epoch 291/1300\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.6397 - val_loss: 0.2263\n",
      "Epoch 292/1300\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.8637 - val_loss: 0.2241\n",
      "Epoch 293/1300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.7124 - val_loss: 0.2220\n",
      "Epoch 294/1300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1491 - val_loss: 0.2198\n",
      "Epoch 295/1300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0730 - val_loss: 0.2175\n",
      "Epoch 296/1300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.1563 - val_loss: 0.2154\n",
      "Epoch 297/1300\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 1.4896 - val_loss: 0.2133\n",
      "Epoch 298/1300\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.2590 - val_loss: 0.2109\n",
      "Epoch 299/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4362 - val_loss: 0.2087\n",
      "Epoch 300/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2067 - val_loss: 0.2062\n",
      "Epoch 301/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1683 - val_loss: 0.2035\n",
      "Epoch 302/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0312 - val_loss: 0.2009\n",
      "Epoch 303/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1124 - val_loss: 0.1982\n",
      "Epoch 304/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1545 - val_loss: 0.1953\n",
      "Epoch 305/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2168 - val_loss: 0.1922\n",
      "Epoch 306/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1352 - val_loss: 0.1889\n",
      "Epoch 307/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0840 - val_loss: 0.1857\n",
      "Epoch 308/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1434 - val_loss: 0.1824\n",
      "Epoch 309/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1052 - val_loss: 0.1794\n",
      "Epoch 310/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2125 - val_loss: 0.1772\n",
      "Epoch 311/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0699 - val_loss: 0.1750\n",
      "Epoch 312/1300\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7855 - val_loss: 0.1731\n",
      "Epoch 313/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1503 - val_loss: 0.1709\n",
      "Epoch 314/1300\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0126 - val_loss: 0.1688\n",
      "Epoch 315/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1818 - val_loss: 0.1665\n",
      "Epoch 316/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1123 - val_loss: 0.1641\n",
      "Epoch 317/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.5172e-04 - val_loss: 0.1619\n",
      "Epoch 318/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0169 - val_loss: 0.1598\n",
      "Epoch 319/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0072 - val_loss: 0.1578\n",
      "Epoch 320/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0537 - val_loss: 0.1558\n",
      "Epoch 321/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4614 - val_loss: 0.1539\n",
      "Epoch 322/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0163 - val_loss: 0.1520\n",
      "Epoch 323/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0314 - val_loss: 0.1501\n",
      "Epoch 324/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0944 - val_loss: 0.1483\n",
      "Epoch 325/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2083 - val_loss: 0.1467\n",
      "Epoch 326/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0253 - val_loss: 0.1451\n",
      "Epoch 327/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0249 - val_loss: 0.1435\n",
      "Epoch 328/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0079 - val_loss: 0.1420\n",
      "Epoch 329/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0742 - val_loss: 0.1402\n",
      "Epoch 330/1300\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0413 - val_loss: 0.1384\n",
      "Epoch 331/1300\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0318 - val_loss: 0.1366\n",
      "Epoch 332/1300\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8383 - val_loss: 0.1349\n",
      "Epoch 333/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0018 - val_loss: 0.1334\n",
      "Epoch 334/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0537 - val_loss: 0.1320\n",
      "Epoch 335/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0195 - val_loss: 0.1306\n",
      "Epoch 336/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1123 - val_loss: 0.1291\n",
      "Epoch 337/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0134 - val_loss: 0.1276\n",
      "Epoch 338/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3831 - val_loss: 0.1262\n",
      "Epoch 339/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3473 - val_loss: 0.1255\n",
      "Epoch 340/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0203 - val_loss: 0.1247\n",
      "Epoch 341/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3500 - val_loss: 0.1240\n",
      "Epoch 342/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7700 - val_loss: 0.1234\n",
      "Epoch 343/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2692e-04 - val_loss: 0.1229\n",
      "Epoch 344/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.7830e-04 - val_loss: 0.1224\n",
      "Epoch 345/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0771 - val_loss: 0.1217\n",
      "Epoch 346/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.4688 - val_loss: 0.1207\n",
      "Epoch 347/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0239 - val_loss: 0.1201\n",
      "Epoch 348/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0233 - val_loss: 0.1193\n",
      "Epoch 349/1300\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0120 - val_loss: 0.1184\n",
      "Epoch 350/1300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0299 - val_loss: 0.1175\n",
      "Epoch 351/1300\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0023 - val_loss: 0.1166\n",
      "Epoch 352/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0108 - val_loss: 0.1157\n",
      "Epoch 353/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0077 - val_loss: 0.1148\n",
      "Epoch 354/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0157 - val_loss: 0.1138\n",
      "Epoch 355/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0017 - val_loss: 0.1129\n",
      "Epoch 356/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4162 - val_loss: 0.1121\n",
      "Epoch 357/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0829 - val_loss: 0.1113\n",
      "Epoch 358/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.8844e-04 - val_loss: 0.1106\n",
      "Epoch 359/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9844 - val_loss: 0.1098\n",
      "Epoch 360/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.1089\n",
      "Epoch 361/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9918e-05 - val_loss: 0.1082\n",
      "Epoch 362/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3680 - val_loss: 0.1075\n",
      "Epoch 363/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0785 - val_loss: 0.1068\n",
      "Epoch 364/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0407 - val_loss: 0.1063\n",
      "Epoch 365/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.5898e-05 - val_loss: 0.1059\n",
      "Epoch 366/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9612 - val_loss: 0.1052\n",
      "Epoch 367/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0027 - val_loss: 0.1046\n",
      "Epoch 368/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0043 - val_loss: 0.1040\n",
      "Epoch 369/1300\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0115 - val_loss: 0.1034\n",
      "Epoch 370/1300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0060 - val_loss: 0.1029\n",
      "Epoch 371/1300\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0021 - val_loss: 0.1023\n",
      "Epoch 372/1300\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.3900 - val_loss: 0.1014\n",
      "Epoch 373/1300\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0426 - val_loss: 0.1007\n",
      "Epoch 374/1300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0036 - val_loss: 0.1001\n",
      "Epoch 375/1300\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0027 - val_loss: 0.0994\n",
      "Epoch 376/1300\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 6.3258e-04 - val_loss: 0.0988\n",
      "Epoch 377/1300\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.1939 - val_loss: 0.0979\n",
      "Epoch 378/1300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6324 - val_loss: 0.0970\n",
      "Epoch 379/1300\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 3.6364e-04 - val_loss: 0.0961\n",
      "Epoch 380/1300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.2059 - val_loss: 0.0950\n",
      "Epoch 381/1300\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 9.4981e-04 - val_loss: 0.0940\n",
      "Epoch 382/1300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 9.2946e-04 - val_loss: 0.0931\n",
      "Epoch 383/1300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 3.4880e-04 - val_loss: 0.0922\n",
      "Epoch 384/1300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 9.2649e-04 - val_loss: 0.0914\n",
      "Epoch 385/1300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0073 - val_loss: 0.0906\n",
      "Epoch 386/1300\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2044 - val_loss: 0.0897\n",
      "Epoch 387/1300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 5.8815e-04 - val_loss: 0.0889\n",
      "Epoch 388/1300\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.1468 - val_loss: 0.0880\n",
      "Epoch 389/1300\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.3351 - val_loss: 0.0871\n",
      "Epoch 390/1300\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 1.7166 - val_loss: 0.0859\n",
      "Epoch 391/1300\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.0168 - val_loss: 0.0848\n",
      "Epoch 392/1300\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6312 - val_loss: 0.0837\n",
      "Epoch 393/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 9.3500e-04 - val_loss: 0.0827\n",
      "Epoch 394/1300\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0359 - val_loss: 0.0816\n",
      "Epoch 395/1300\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0016 - val_loss: 0.0806\n",
      "Epoch 396/1300\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0052 - val_loss: 0.0797\n",
      "Epoch 397/1300\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9956 - val_loss: 0.0784\n",
      "Epoch 398/1300\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1202 - val_loss: 0.0773\n",
      "Epoch 399/1300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1219 - val_loss: 0.0761\n",
      "Epoch 400/1300\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1154 - val_loss: 0.0750\n",
      "Epoch 401/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0076 - val_loss: 0.0740\n",
      "Epoch 402/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.3680e-04 - val_loss: 0.0731\n",
      "Epoch 403/1300\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.1498e-06 - val_loss: 0.0723\n",
      "Epoch 404/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step - loss: 1.5372e-05 - val_loss: 0.0715\n",
      "Epoch 405/1300\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8971 - val_loss: 0.0706\n",
      "Epoch 406/1300\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 6.3648e-04 - val_loss: 0.0697\n",
      "Epoch 407/1300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2466 - val_loss: 0.0688\n",
      "Epoch 408/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0014 - val_loss: 0.0680\n",
      "Epoch 409/1300\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0013 - val_loss: 0.0672\n",
      "Epoch 410/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2376 - val_loss: 0.0665\n",
      "Epoch 411/1300\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.3628 - val_loss: 0.0654\n",
      "Epoch 412/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0829e-04 - val_loss: 0.0644\n",
      "Epoch 413/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0455 - val_loss: 0.0633\n",
      "Epoch 414/1300\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0017 - val_loss: 0.0624\n",
      "Epoch 415/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0237 - val_loss: 0.0614\n",
      "Epoch 416/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0022 - val_loss: 0.0605\n",
      "Epoch 417/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.5103e-05 - val_loss: 0.0596\n",
      "Epoch 418/1300\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0023 - val_loss: 0.0590\n",
      "Epoch 419/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0500 - val_loss: 0.0585\n",
      "Epoch 420/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - val_loss: 0.0581\n",
      "Epoch 421/1300\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 9.2774e-05 - val_loss: 0.0577\n",
      "Epoch 422/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0016 - val_loss: 0.0574\n",
      "Epoch 423/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.3340 - val_loss: 0.0566\n",
      "Epoch 424/1300\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0205 - val_loss: 0.0559\n",
      "Epoch 425/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.5125e-05 - val_loss: 0.0553\n",
      "Epoch 426/1300\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5843 - val_loss: 0.0545\n",
      "Epoch 427/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0011 - val_loss: 0.0538\n",
      "Epoch 428/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.3194e-05 - val_loss: 0.0531\n",
      "Epoch 429/1300\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - val_loss: 0.0525\n",
      "Epoch 430/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.5431e-04 - val_loss: 0.0520\n",
      "Epoch 431/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0151 - val_loss: 0.0515\n",
      "Epoch 432/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4054 - val_loss: 0.0510\n",
      "Epoch 433/1300\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4.4741e-05 - val_loss: 0.0506\n",
      "Epoch 434/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.4706e-05 - val_loss: 0.0502\n",
      "Epoch 435/1300\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.5026e-05 - val_loss: 0.0499\n",
      "Epoch 436/1300\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2132e-0 - 0s 203ms/step - loss: 4.2132e-05 - val_loss: 0.0496\n",
      "Epoch 437/1300\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.0310 - val_loss: 0.0491\n",
      "Epoch 438/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0110 - val_loss: 0.0487\n",
      "Epoch 439/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 0.0483\n",
      "Epoch 440/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0047 - val_loss: 0.0479\n",
      "Epoch 441/1300\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0445 - val_loss: 0.0473\n",
      "Epoch 442/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - val_loss: 0.0469\n",
      "Epoch 443/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 6.7061e-05 - val_loss: 0.0465\n",
      "Epoch 444/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6410 - val_loss: 0.0461\n",
      "Epoch 445/1300\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2945 - val_loss: 0.0458\n",
      "Epoch 446/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4191 - val_loss: 0.0457\n",
      "Epoch 447/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.2783e-06 - val_loss: 0.0456\n",
      "Epoch 448/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - val_loss: 0.0456\n",
      "Epoch 449/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1237 - val_loss: 0.0456\n",
      "Epoch 450/1300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 7.4569e-04 - val_loss: 0.0456\n",
      "Epoch 451/1300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.2936 - val_loss: 0.0458\n",
      "Epoch 452/1300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0051 - val_loss: 0.0460\n",
      "Epoch 453/1300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0057 - val_loss: 0.0463\n",
      "Epoch 454/1300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0019 - val_loss: 0.0466\n",
      "Epoch 455/1300\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4855 - val_loss: 0.0474\n",
      "Epoch 456/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0027 - val_loss: 0.0481\n",
      "Epoch 457/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5145e-04 - val_loss: 0.0488\n",
      "Epoch 458/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - val_loss: 0.0495\n",
      "Epoch 459/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0021 - val_loss: 0.0502\n",
      "Epoch 460/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0290 - val_loss: 0.0508\n",
      "Epoch 461/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.6623e-04 - val_loss: 0.0515\n",
      "Epoch 462/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0070 - val_loss: 0.0519\n",
      "Epoch 463/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3627 - val_loss: 0.0525\n",
      "Epoch 464/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0015 - val_loss: 0.0531\n",
      "Epoch 465/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0043 - val_loss: 0.0535\n",
      "Epoch 466/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4307 - val_loss: 0.0546\n",
      "Epoch 467/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0287 - val_loss: 0.0558\n",
      "Epoch 468/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0331 - val_loss: 0.0566\n",
      "Epoch 469/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0037 - val_loss: 0.0573\n",
      "Epoch 470/1300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0362 - val_loss: 0.0579\n",
      "Epoch 471/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1446 - val_loss: 0.0580\n",
      "Epoch 472/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2805 - val_loss: 0.0585\n",
      "Epoch 473/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.5272e-05 - val_loss: 0.0589\n",
      "Epoch 474/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.1382e-04 - val_loss: 0.0593\n",
      "Epoch 475/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.9980e-04 - val_loss: 0.0597\n",
      "Epoch 476/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0344 - val_loss: 0.0599\n",
      "Epoch 477/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0341 - val_loss: 0.0601\n",
      "Epoch 478/1300\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1900 - val_loss: 0.0599\n",
      "Epoch 479/1300\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0174 - val_loss: 0.0594\n",
      "Epoch 480/1300\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1660 - val_loss: 0.0592\n",
      "Epoch 481/1300\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 8.6927e-04 - val_loss: 0.0591\n",
      "Epoch 482/1300\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1677 - val_loss: 0.0593\n",
      "Epoch 483/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.8608e-04 - val_loss: 0.0595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484/1300\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5664 - val_loss: 0.0602\n",
      "Epoch 485/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.9004e-05 - val_loss: 0.0608\n",
      "Epoch 486/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - val_loss: 0.0611\n",
      "Epoch 487/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0163 - val_loss: 0.0611\n",
      "Epoch 488/1300\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0054 - val_loss: 0.0609\n",
      "Epoch 489/1300\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.3359 - val_loss: 0.0610\n",
      "Epoch 490/1300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0017 - val_loss: 0.0609\n",
      "Epoch 491/1300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 3.3317e-04 - val_loss: 0.0609\n",
      "Epoch 492/1300\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.2000e-05 - val_loss: 0.0610\n",
      "Epoch 493/1300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0012 - val_loss: 0.0610\n",
      "Epoch 494/1300\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0058 - val_loss: 0.0608\n",
      "Epoch 495/1300\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0773 - val_loss: 0.0608\n",
      "Epoch 496/1300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4351 - val_loss: 0.0615\n",
      "Epoch 497/1300\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0018 - val_loss: 0.0622\n",
      "Epoch 498/1300\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0025 - val_loss: 0.0627\n",
      "Epoch 499/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0614 - val_loss: 0.0637\n",
      "Epoch 500/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3070 - val_loss: 0.0649\n",
      "Epoch 501/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0265 - val_loss: 0.0657\n",
      "Epoch 502/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0356 - val_loss: 0.0667\n",
      "Epoch 503/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1549 - val_loss: 0.0682\n",
      "Epoch 504/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0044 - val_loss: 0.0698\n",
      "Epoch 505/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0339 - val_loss: 0.0715\n",
      "Epoch 506/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1294 - val_loss: 0.0737\n",
      "Epoch 507/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.2503e-04 - val_loss: 0.0757\n",
      "Epoch 508/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.4670e-04 - val_loss: 0.0777\n",
      "Epoch 509/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0723 - val_loss: 0.0790\n",
      "Epoch 510/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0103 - val_loss: 0.0805\n",
      "Epoch 511/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0499 - val_loss: 0.0821\n",
      "Epoch 512/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.6295e-04 - val_loss: 0.0837\n",
      "Epoch 513/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.7987e-04 - val_loss: 0.0852\n",
      "Epoch 514/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 8.0965e-04 - val_loss: 0.0865\n",
      "Epoch 515/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0040 - val_loss: 0.0878\n",
      "Epoch 516/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0019 - val_loss: 0.0892\n",
      "Epoch 517/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0722 - val_loss: 0.0912\n",
      "Epoch 518/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0071 - val_loss: 0.0928\n",
      "Epoch 519/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0670 - val_loss: 0.0951\n",
      "Epoch 520/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - val_loss: 0.0974\n",
      "Epoch 521/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.0994\n",
      "Epoch 522/1300\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0040 - val_loss: 0.1011\n",
      "Epoch 523/1300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0032 - val_loss: 0.1025\n",
      "Epoch 524/1300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0019 - val_loss: 0.1040\n",
      "Epoch 525/1300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 7.0616e-04 - val_loss: 0.1053\n",
      "Epoch 526/1300\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 7.2209e-04 - val_loss: 0.1065\n",
      "Epoch 527/1300\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0329 - val_loss: 0.1079\n",
      "Epoch 528/1300\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0062 - val_loss: 0.1090\n",
      "Epoch 529/1300\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0599 - val_loss: 0.1115\n",
      "Epoch 530/1300\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0714 - val_loss: 0.1144\n",
      "Epoch 531/1300\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0028 - val_loss: 0.1172\n",
      "Epoch 532/1300\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0053 - val_loss: 0.1200\n",
      "Epoch 533/1300\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0026 - val_loss: 0.1228\n",
      "Epoch 534/1300\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.5719 - val_loss: 0.1185\n",
      "Epoch 535/1300\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 2.4407e-04 - val_loss: 0.1150\n",
      "Epoch 536/1300\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0017 - val_loss: 0.1118\n",
      "Epoch 537/1300\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 5.9592e-04 - val_loss: 0.1090\n",
      "Epoch 538/1300\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0736 - val_loss: 0.1062\n",
      "Epoch 539/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 0.1038\n",
      "Epoch 540/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0026 - val_loss: 0.1018\n",
      "Epoch 541/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.3878e-04 - val_loss: 0.1001\n",
      "Epoch 542/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.0956e-04 - val_loss: 0.0985\n",
      "Epoch 543/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0935 - val_loss: 0.0983\n",
      "Epoch 544/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0048 - val_loss: 0.0982\n",
      "Epoch 545/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0011 - val_loss: 0.0980\n",
      "Epoch 546/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.3419e-04 - val_loss: 0.0978\n",
      "Epoch 547/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6440 - val_loss: 0.0940\n",
      "Epoch 548/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0628 - val_loss: 0.0912\n",
      "Epoch 549/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0105 - val_loss: 0.0890\n",
      "Epoch 550/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5950 - val_loss: 0.0856\n",
      "Epoch 551/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0027 - val_loss: 0.0827\n",
      "Epoch 552/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0906 - val_loss: 0.0806\n",
      "Epoch 553/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0969 - val_loss: 0.0792\n",
      "Epoch 554/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0027 - val_loss: 0.0779\n",
      "Epoch 555/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1058 - val_loss: 0.0771\n",
      "Epoch 556/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1084 - val_loss: 0.0768\n",
      "Epoch 557/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0346 - val_loss: 0.0764\n",
      "Epoch 558/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0013 - val_loss: 0.0760\n",
      "Epoch 559/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0012 - val_loss: 0.0757\n",
      "Epoch 560/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2238 - val_loss: 0.0762\n",
      "Epoch 561/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0014 - val_loss: 0.0767\n",
      "Epoch 562/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0913 - val_loss: 0.0763\n",
      "Epoch 563/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.0759\n",
      "Epoch 564/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0159 - val_loss: 0.0757\n",
      "Epoch 565/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4585 - val_loss: 0.0743\n",
      "Epoch 566/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0026 - val_loss: 0.0732\n",
      "Epoch 567/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0681 - val_loss: 0.0719\n",
      "Epoch 568/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0096 - val_loss: 0.0709\n",
      "Epoch 569/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6579e-04 - val_loss: 0.0700\n",
      "Epoch 570/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0028 - val_loss: 0.0694\n",
      "Epoch 571/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3185 - val_loss: 0.0694\n",
      "Epoch 572/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.4667e-05 - val_loss: 0.0695\n",
      "Epoch 573/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0016 - val_loss: 0.0696\n",
      "Epoch 574/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - val_loss: 0.0699\n",
      "Epoch 575/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.1439e-04 - val_loss: 0.0700\n",
      "Epoch 576/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0032 - val_loss: 0.0703\n",
      "Epoch 577/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.3455e-05 - val_loss: 0.0705\n",
      "Epoch 578/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1183 - val_loss: 0.0702\n",
      "Epoch 579/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0689 - val_loss: 0.0695\n",
      "Epoch 580/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0078 - val_loss: 0.0691\n",
      "Epoch 581/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0811e-04 - val_loss: 0.0687\n",
      "Epoch 582/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2871 - val_loss: 0.0686\n",
      "Epoch 583/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0635 - val_loss: 0.0682\n",
      "Epoch 584/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3201 - val_loss: 0.0684\n",
      "Epoch 585/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0034 - val_loss: 0.0686\n",
      "Epoch 586/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.7227e-05 - val_loss: 0.0688\n",
      "Epoch 587/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3422 - val_loss: 0.0696\n",
      "Epoch 588/1300\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0124 - val_loss: 0.0706\n",
      "Epoch 589/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5773e-04 - val_loss: 0.0715\n",
      "Epoch 590/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0469 - val_loss: 0.0725\n",
      "Epoch 591/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2421 - val_loss: 0.0742\n",
      "Epoch 592/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0295 - val_loss: 0.0754\n",
      "Epoch 593/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0674 - val_loss: 0.0762\n",
      "Epoch 594/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 7.7310e-04 - val_loss: 0.0768\n",
      "Epoch 595/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - val_loss: 0.0775\n",
      "Epoch 596/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.5805e-04 - val_loss: 0.0782\n",
      "Epoch 597/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - val_loss: 0.0787\n",
      "Epoch 598/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - val_loss: 0.0790\n",
      "Epoch 599/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2902 - val_loss: 0.0799\n",
      "Epoch 600/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026 - val_loss: 0.0808\n",
      "Epoch 601/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0445 - val_loss: 0.0817\n",
      "Epoch 602/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0046 - val_loss: 0.0827\n",
      "Epoch 603/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.7734e-05 - val_loss: 0.0836\n",
      "Epoch 604/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0025 - val_loss: 0.0845\n",
      "Epoch 605/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0413 - val_loss: 0.0855\n",
      "Epoch 606/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3278 - val_loss: 0.0872\n",
      "Epoch 607/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1184 - val_loss: 0.0884\n",
      "Epoch 608/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.8311e-04 - val_loss: 0.0896\n",
      "Epoch 609/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1034 - val_loss: 0.0911\n",
      "Epoch 610/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1019 - val_loss: 0.0928\n",
      "Epoch 611/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0085 - val_loss: 0.0941\n",
      "Epoch 612/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2167 - val_loss: 0.0937\n",
      "Epoch 613/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2430 - val_loss: 0.0937\n",
      "Epoch 614/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2516 - val_loss: 0.0942\n",
      "Epoch 615/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0688 - val_loss: 0.0951\n",
      "Epoch 616/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0398 - val_loss: 0.0955\n",
      "Epoch 617/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4337e-04 - val_loss: 0.0958\n",
      "Epoch 618/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0500 - val_loss: 0.0960\n",
      "Epoch 619/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0051 - val_loss: 0.0961\n",
      "Epoch 620/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8886e-04 - val_loss: 0.0961\n",
      "Epoch 621/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0042 - val_loss: 0.0960\n",
      "Epoch 622/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - val_loss: 0.0959\n",
      "Epoch 623/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0072 - val_loss: 0.0957\n",
      "Epoch 624/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0954\n",
      "Epoch 625/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0078 - val_loss: 0.0950\n",
      "Epoch 626/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - val_loss: 0.0947\n",
      "Epoch 627/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.5936e-05 - val_loss: 0.0945\n",
      "Epoch 628/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.0120e-06 - val_loss: 0.0943\n",
      "Epoch 629/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0023 - val_loss: 0.0942\n",
      "Epoch 630/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1730 - val_loss: 0.0950\n",
      "Epoch 631/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.4822e-04 - val_loss: 0.0957\n",
      "Epoch 632/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1196 - val_loss: 0.0959\n",
      "Epoch 633/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6035e-04 - val_loss: 0.0961\n",
      "Epoch 634/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0345 - val_loss: 0.0966\n",
      "Epoch 635/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.8144e-05 - val_loss: 0.0971\n",
      "Epoch 636/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0252 - val_loss: 0.0973\n",
      "Epoch 637/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.5836e-04 - val_loss: 0.0975\n",
      "Epoch 638/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4228e-04 - val_loss: 0.0978\n",
      "Epoch 639/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6814 - val_loss: 0.0960\n",
      "Epoch 640/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0609 - val_loss: 0.0949\n",
      "Epoch 641/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 0.0939\n",
      "Epoch 642/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.1391e-05 - val_loss: 0.0930\n",
      "Epoch 643/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 0.0921\n",
      "Epoch 644/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 0.0913\n",
      "Epoch 645/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0907\n",
      "Epoch 646/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1035 - val_loss: 0.0898\n",
      "Epoch 647/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - val_loss: 0.0890\n",
      "Epoch 648/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.0363e-04 - val_loss: 0.0884\n",
      "Epoch 649/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0070 - val_loss: 0.0879\n",
      "Epoch 650/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0912 - val_loss: 0.0877\n",
      "Epoch 651/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6078 - val_loss: 0.0860\n",
      "Epoch 652/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1011 - val_loss: 0.0849\n",
      "Epoch 653/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8880e-04 - val_loss: 0.0838\n",
      "Epoch 654/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0970 - val_loss: 0.0831\n",
      "Epoch 655/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0124e-04 - val_loss: 0.0825\n",
      "Epoch 656/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0988 - val_loss: 0.0822\n",
      "Epoch 657/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.1248e-04 - val_loss: 0.0820\n",
      "Epoch 658/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0395 - val_loss: 0.0819\n",
      "Epoch 659/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5567 - val_loss: 0.0805\n",
      "Epoch 660/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.8967e-04 - val_loss: 0.0794\n",
      "Epoch 661/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0061 - val_loss: 0.0784\n",
      "Epoch 662/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0063 - val_loss: 0.0776\n",
      "Epoch 663/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.0812e-04 - val_loss: 0.0770\n",
      "Epoch 664/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0248 - val_loss: 0.0765\n",
      "Epoch 665/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5087 - val_loss: 0.0748\n",
      "Epoch 666/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1013 - val_loss: 0.0737\n",
      "Epoch 667/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3073 - val_loss: 0.0716\n",
      "Epoch 668/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0074 - val_loss: 0.0700\n",
      "Epoch 669/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0495 - val_loss: 0.0686\n",
      "Epoch 670/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - val_loss: 0.0676\n",
      "Epoch 671/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2344e-05 - val_loss: 0.0667\n",
      "Epoch 672/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.9935e-04 - val_loss: 0.0659\n",
      "Epoch 673/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.9356e-04 - val_loss: 0.0652\n",
      "Epoch 674/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 0.0647\n",
      "Epoch 675/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.0643\n",
      "Epoch 676/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2854 - val_loss: 0.0642\n",
      "Epoch 677/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.3979e-04 - val_loss: 0.0641\n",
      "Epoch 678/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 0.0640\n",
      "Epoch 679/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1506e-07 - val_loss: 0.0639\n",
      "Epoch 680/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - val_loss: 0.0638\n",
      "Epoch 681/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0022 - val_loss: 0.0637\n",
      "Epoch 682/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.3512e-05 - val_loss: 0.0637\n",
      "Epoch 683/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3473e-04 - val_loss: 0.0636\n",
      "Epoch 684/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3245 - val_loss: 0.0632\n",
      "Epoch 685/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2915 - val_loss: 0.0630\n",
      "Epoch 686/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0657 - val_loss: 0.0627\n",
      "Epoch 687/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1742 - val_loss: 0.0626\n",
      "Epoch 688/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 0.0625\n",
      "Epoch 689/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0625\n",
      "Epoch 690/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1111e-04 - val_loss: 0.0624\n",
      "Epoch 691/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1779 - val_loss: 0.0625\n",
      "Epoch 692/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 0.0626\n",
      "Epoch 693/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0489e-04 - val_loss: 0.0626\n",
      "Epoch 694/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 0.0625\n",
      "Epoch 695/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1758 - val_loss: 0.0627\n",
      "Epoch 696/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1048e-04 - val_loss: 0.0628\n",
      "Epoch 697/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0070 - val_loss: 0.0627\n",
      "Epoch 698/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 0.0626\n",
      "Epoch 699/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.5556e-05 - val_loss: 0.0625\n",
      "Epoch 700/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - val_loss: 0.0625\n",
      "Epoch 701/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0593 - val_loss: 0.0625\n",
      "Epoch 702/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0649 - val_loss: 0.0623\n",
      "Epoch 703/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - val_loss: 0.0621\n",
      "Epoch 704/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.0619\n",
      "Epoch 705/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0616\n",
      "Epoch 706/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0051 - val_loss: 0.0613\n",
      "Epoch 707/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4423e-04 - val_loss: 0.0610\n",
      "Epoch 708/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.0608\n",
      "Epoch 709/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.1138e-04 - val_loss: 0.0606\n",
      "Epoch 710/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6740e-04 - val_loss: 0.0605\n",
      "Epoch 711/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0048 - val_loss: 0.0604\n",
      "Epoch 712/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 0.0603\n",
      "Epoch 713/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0955 - val_loss: 0.0600\n",
      "Epoch 714/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0578 - val_loss: 0.0598\n",
      "Epoch 715/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0069 - val_loss: 0.0597\n",
      "Epoch 716/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0662 - val_loss: 0.0595\n",
      "Epoch 717/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0478 - val_loss: 0.0592\n",
      "Epoch 718/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3739 - val_loss: 0.0594\n",
      "Epoch 719/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0055 - val_loss: 0.0597\n",
      "Epoch 720/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050 - val_loss: 0.0599\n",
      "Epoch 721/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0057 - val_loss: 0.0602\n",
      "Epoch 722/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0386 - val_loss: 0.0605\n",
      "Epoch 723/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0379 - val_loss: 0.0609\n",
      "Epoch 724/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0130 - val_loss: 0.0613\n",
      "Epoch 725/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0010 - val_loss: 0.0617\n",
      "Epoch 726/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0525 - val_loss: 0.0621\n",
      "Epoch 727/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0076 - val_loss: 0.0625\n",
      "Epoch 728/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0074 - val_loss: 0.0629\n",
      "Epoch 729/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0024 - val_loss: 0.0634\n",
      "Epoch 730/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.7575e-04 - val_loss: 0.0639\n",
      "Epoch 731/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0922 - val_loss: 0.0640\n",
      "Epoch 732/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0015 - val_loss: 0.0642\n",
      "Epoch 733/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0321 - val_loss: 0.0643\n",
      "Epoch 734/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.1987e-06 - val_loss: 0.0644\n",
      "Epoch 735/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0047 - val_loss: 0.0645\n",
      "Epoch 736/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0531 - val_loss: 0.0647\n",
      "Epoch 737/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.2387e-06 - val_loss: 0.0649\n",
      "Epoch 738/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1505 - val_loss: 0.0653\n",
      "Epoch 739/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.0656\n",
      "Epoch 740/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0526 - val_loss: 0.0656\n",
      "Epoch 741/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0014 - val_loss: 0.0657\n",
      "Epoch 742/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0010 - val_loss: 0.0658\n",
      "Epoch 743/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.0573e-04 - val_loss: 0.0658\n",
      "Epoch 744/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0096 - val_loss: 0.0659\n",
      "Epoch 745/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.9972e-04 - val_loss: 0.0660\n",
      "Epoch 746/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.7521e-04 - val_loss: 0.0661\n",
      "Epoch 747/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0189 - val_loss: 0.0661\n",
      "Epoch 748/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0892 - val_loss: 0.0658\n",
      "Epoch 749/1300\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0466 - val_loss: 0.0655\n",
      "Epoch 750/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0124 - val_loss: 0.0653\n",
      "Epoch 751/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0090 - val_loss: 0.0652\n",
      "Epoch 752/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2797 - val_loss: 0.0657\n",
      "Epoch 753/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0072 - val_loss: 0.0662\n",
      "Epoch 754/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0056 - val_loss: 0.0667\n",
      "Epoch 755/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0459 - val_loss: 0.0668\n",
      "Epoch 756/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0465 - val_loss: 0.0665\n",
      "Epoch 757/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2710 - val_loss: 0.0665\n",
      "Epoch 758/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.5617e-04 - val_loss: 0.0664\n",
      "Epoch 759/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0094 - val_loss: 0.0664\n",
      "Epoch 760/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0020 - val_loss: 0.0664\n",
      "Epoch 761/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0023 - val_loss: 0.0664\n",
      "Epoch 762/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.6195e-04 - val_loss: 0.0665\n",
      "Epoch 763/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0026 - val_loss: 0.0665\n",
      "Epoch 764/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.8543e-05 - val_loss: 0.0666\n",
      "Epoch 765/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0483 - val_loss: 0.0668\n",
      "Epoch 766/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0048 - val_loss: 0.0670\n",
      "Epoch 767/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.5706e-04 - val_loss: 0.0672\n",
      "Epoch 768/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3233 - val_loss: 0.0677\n",
      "Epoch 769/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2660 - val_loss: 0.0688\n",
      "Epoch 770/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0032 - val_loss: 0.0697\n",
      "Epoch 771/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.9943e-04 - val_loss: 0.0706\n",
      "Epoch 772/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - val_loss: 0.0714\n",
      "Epoch 773/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0029 - val_loss: 0.0722\n",
      "Epoch 774/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0041 - val_loss: 0.0728\n",
      "Epoch 775/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0428 - val_loss: 0.0735\n",
      "Epoch 776/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0961 - val_loss: 0.0737\n",
      "Epoch 777/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0024 - val_loss: 0.0741\n",
      "Epoch 778/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0022 - val_loss: 0.0743\n",
      "Epoch 779/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4811 - val_loss: 0.0736\n",
      "Epoch 780/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2552 - val_loss: 0.0733\n",
      "Epoch 781/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0040 - val_loss: 0.0730\n",
      "Epoch 782/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0775 - val_loss: 0.0722\n",
      "Epoch 783/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0422 - val_loss: 0.0716\n",
      "Epoch 784/1300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0123 - val_loss: 0.0711\n",
      "Epoch 785/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0998 - val_loss: 0.0705\n",
      "Epoch 786/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0030 - val_loss: 0.0701\n",
      "Epoch 787/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.9095e-04 - val_loss: 0.0697\n",
      "Epoch 788/1300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.3774e-04 - val_loss: 0.0695\n",
      "Epoch 789/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.1210e-04 - val_loss: 0.0692\n",
      "Epoch 790/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0010 - val_loss: 0.0690\n",
      "Epoch 791/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0930 - val_loss: 0.0686\n",
      "Epoch 792/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0951 - val_loss: 0.0680\n",
      "Epoch 793/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0043 - val_loss: 0.0674\n",
      "Epoch 794/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.6382e-04 - val_loss: 0.0668\n",
      "Epoch 795/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.3690e-04 - val_loss: 0.0663\n",
      "Epoch 796/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3269 - val_loss: 0.0662\n",
      "Epoch 797/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - val_loss: 0.0662\n",
      "Epoch 798/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2787 - val_loss: 0.0668\n",
      "Epoch 799/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2680 - val_loss: 0.0675\n",
      "Epoch 800/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3134e-04 - val_loss: 0.0682\n",
      "Epoch 801/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0455 - val_loss: 0.0684\n",
      "Epoch 802/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0011 - val_loss: 0.0687\n",
      "Epoch 803/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0488 - val_loss: 0.0687\n",
      "Epoch 804/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0485 - val_loss: 0.0684\n",
      "Epoch 805/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.3365e-04 - val_loss: 0.0680\n",
      "Epoch 806/1300\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0470 - val_loss: 0.0676\n",
      "Epoch 807/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2217 - val_loss: 0.0664\n",
      "Epoch 808/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0441 - val_loss: 0.0652\n",
      "Epoch 809/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1286 - val_loss: 0.0644\n",
      "Epoch 810/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.5480e-04 - val_loss: 0.0637\n",
      "Epoch 811/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0863 - val_loss: 0.0630\n",
      "Epoch 812/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1768 - val_loss: 0.0619\n",
      "Epoch 813/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - val_loss: 0.0609\n",
      "Epoch 814/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042 - val_loss: 0.0601\n",
      "Epoch 815/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0778 - val_loss: 0.0592\n",
      "Epoch 816/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.4244e-04 - val_loss: 0.0585\n",
      "Epoch 817/1300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0738 - val_loss: 0.0578\n",
      "Epoch 818/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0150 - val_loss: 0.0572\n",
      "Epoch 819/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - val_loss: 0.0568\n",
      "Epoch 820/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1719 - val_loss: 0.0565\n",
      "Epoch 821/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 7.6942e-04 - val_loss: 0.0563\n",
      "Epoch 822/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0282 - val_loss: 0.0561\n",
      "Epoch 823/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0663 - val_loss: 0.0559\n",
      "Epoch 824/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0068 - val_loss: 0.0557\n",
      "Epoch 825/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.8722e-04 - val_loss: 0.0555\n",
      "Epoch 826/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2889 - val_loss: 0.0551\n",
      "Epoch 827/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0174 - val_loss: 0.0547\n",
      "Epoch 828/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.1318e-04 - val_loss: 0.0543\n",
      "Epoch 829/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3918 - val_loss: 0.0543\n",
      "Epoch 830/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 7.7885e-04 - val_loss: 0.0543\n",
      "Epoch 831/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0952 - val_loss: 0.0545\n",
      "Epoch 832/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0577 - val_loss: 0.0547\n",
      "Epoch 833/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0028 - val_loss: 0.0549\n",
      "Epoch 834/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 6.8076e-05 - val_loss: 0.0551\n",
      "Epoch 835/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0917e-04 - val_loss: 0.0553\n",
      "Epoch 836/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0012 - val_loss: 0.0555\n",
      "Epoch 837/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.0876e-04 - val_loss: 0.0557\n",
      "Epoch 838/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1201e-04 - val_loss: 0.0558\n",
      "Epoch 839/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0044 - val_loss: 0.0560\n",
      "Epoch 840/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0047 - val_loss: 0.0563\n",
      "Epoch 841/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0308 - val_loss: 0.0564\n",
      "Epoch 842/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0042 - val_loss: 0.0564\n",
      "Epoch 843/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0015 - val_loss: 0.0563\n",
      "Epoch 844/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0986 - val_loss: 0.0559\n",
      "Epoch 845/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2272 - val_loss: 0.0558\n",
      "Epoch 846/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2504 - val_loss: 0.0555\n",
      "Epoch 847/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1716 - val_loss: 0.0552\n",
      "Epoch 848/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 6.7074e-04 - val_loss: 0.0550\n",
      "Epoch 849/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0542 - val_loss: 0.0548\n",
      "Epoch 850/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0540 - val_loss: 0.0545\n",
      "Epoch 851/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.8800e-04 - val_loss: 0.0543\n",
      "Epoch 852/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 7.7679e-05 - val_loss: 0.0541\n",
      "Epoch 853/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0062 - val_loss: 0.0539\n",
      "Epoch 854/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0170 - val_loss: 0.0538\n",
      "Epoch 855/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.5140e-05 - val_loss: 0.0537\n",
      "Epoch 856/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.5608e-04 - val_loss: 0.0537\n",
      "Epoch 857/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.7556e-04 - val_loss: 0.0536\n",
      "Epoch 858/1300\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2136 - val_loss: 0.0537\n",
      "Epoch 859/1300\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0238 - val_loss: 0.0536\n",
      "Epoch 860/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - val_loss: 0.0535\n",
      "Epoch 861/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.4857e-04 - val_loss: 0.0534\n",
      "Epoch 862/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0663 - val_loss: 0.0534\n",
      "Epoch 863/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0421 - val_loss: 0.0533\n",
      "Epoch 864/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0496 - val_loss: 0.0530\n",
      "Epoch 865/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 7.7597e-04 - val_loss: 0.0528\n",
      "Epoch 866/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1723 - val_loss: 0.0526\n",
      "Epoch 867/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4591 - val_loss: 0.0529\n",
      "Epoch 868/1300\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - val_loss: 0.0531\n",
      "Epoch 869/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0128 - val_loss: 0.0534\n",
      "Epoch 870/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0023 - val_loss: 0.0537\n",
      "Epoch 871/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.0612e-04 - val_loss: 0.0539\n",
      "Epoch 872/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4290 - val_loss: 0.0545\n",
      "Epoch 873/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.5962e-04 - val_loss: 0.0551\n",
      "Epoch 874/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0020 - val_loss: 0.0557\n",
      "Epoch 875/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3992 - val_loss: 0.0566\n",
      "Epoch 876/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0176 - val_loss: 0.0574\n",
      "Epoch 877/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0019 - val_loss: 0.0581\n",
      "Epoch 878/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3864 - val_loss: 0.0592\n",
      "Epoch 879/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0049 - val_loss: 0.0603\n",
      "Epoch 880/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 7.9035e-05 - val_loss: 0.0613\n",
      "Epoch 881/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0024 - val_loss: 0.0623\n",
      "Epoch 882/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0820 - val_loss: 0.0630\n",
      "Epoch 883/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1300 - val_loss: 0.0639\n",
      "Epoch 884/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3463 - val_loss: 0.0640\n",
      "Epoch 885/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0436 - val_loss: 0.0642\n",
      "Epoch 886/1300\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0042 - val_loss: 0.0644\n",
      "Epoch 887/1300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0293 - val_loss: 0.0644\n",
      "Epoch 888/1300\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 7.0095e-04 - val_loss: 0.0643\n",
      "Epoch 889/1300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0040 - val_loss: 0.0643\n",
      "Epoch 890/1300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4474 - val_loss: 0.0648\n",
      "Epoch 891/1300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0046 - val_loss: 0.0653\n",
      "Epoch 892/1300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0043 - val_loss: 0.0657\n",
      "Epoch 893/1300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0063 - val_loss: 0.0662\n",
      "Epoch 894/1300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0057 - val_loss: 0.0666\n",
      "Epoch 895/1300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0057 - val_loss: 0.0671\n",
      "Epoch 896/1300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0267 - val_loss: 0.0673\n",
      "Epoch 897/1300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 3.6294e-05 - val_loss: 0.0675\n",
      "Epoch 898/1300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1736 - val_loss: 0.0670\n",
      "Epoch 899/1300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3720 - val_loss: 0.0662\n",
      "Epoch 900/1300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.1229e-04 - val_loss: 0.0655\n",
      "Epoch 901/1300\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0591 - val_loss: 0.0645\n",
      "Epoch 902/1300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0016 - val_loss: 0.0637\n",
      "Epoch 903/1300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1036 - val_loss: 0.0626\n",
      "Epoch 904/1300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 3.0695e-04 - val_loss: 0.0617\n",
      "Epoch 905/1300\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0077 - val_loss: 0.0607\n",
      "Epoch 906/1300\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0027 - val_loss: 0.0599\n",
      "Epoch 907/1300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 6.8732e-04 - val_loss: 0.0591\n",
      "Epoch 908/1300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2351 - val_loss: 0.0581\n",
      "Epoch 909/1300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0033 - val_loss: 0.0573\n",
      "Epoch 910/1300\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0021 - val_loss: 0.0567\n",
      "Epoch 911/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0443 - val_loss: 0.0561\n",
      "Epoch 912/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0039 - val_loss: 0.0556\n",
      "Epoch 913/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0462 - val_loss: 0.0552\n",
      "Epoch 914/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - val_loss: 0.0548\n",
      "Epoch 915/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0847 - val_loss: 0.0543\n",
      "Epoch 916/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0101 - val_loss: 0.0540\n",
      "Epoch 917/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.6186e-04 - val_loss: 0.0536\n",
      "Epoch 918/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0466 - val_loss: 0.0532\n",
      "Epoch 919/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0016 - val_loss: 0.0528\n",
      "Epoch 920/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1720 - val_loss: 0.0526\n",
      "Epoch 921/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0021 - val_loss: 0.0524\n",
      "Epoch 922/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0517 - val_loss: 0.0523\n",
      "Epoch 923/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0354 - val_loss: 0.0521\n",
      "Epoch 924/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0024e-04 - val_loss: 0.0519\n",
      "Epoch 925/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.0956e-04 - val_loss: 0.0518\n",
      "Epoch 926/1300\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.4253 - val_loss: 0.0519\n",
      "Epoch 927/1300\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0520 - val_loss: 0.0519\n",
      "Epoch 928/1300\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.4823 - val_loss: 0.0522\n",
      "Epoch 929/1300\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.2136 - val_loss: 0.0526\n",
      "Epoch 930/1300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4842 - val_loss: 0.0531\n",
      "Epoch 931/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - val_loss: 0.0537\n",
      "Epoch 932/1300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2010 - val_loss: 0.0544\n",
      "Epoch 933/1300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1826 - val_loss: 0.0552\n",
      "Epoch 934/1300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0138 - val_loss: 0.0559\n",
      "Epoch 935/1300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 4.4227e-06 - val_loss: 0.0567\n",
      "Epoch 936/1300\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0160 - val_loss: 0.0575\n",
      "Epoch 937/1300\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.1622e-04 - val_loss: 0.0583\n",
      "Epoch 938/1300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1492 - val_loss: 0.0592\n",
      "Epoch 939/1300\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2420 - val_loss: 0.0596\n",
      "Epoch 940/1300\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 6.1062e-05 - val_loss: 0.0600\n",
      "Epoch 941/1300\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.9092e-04 - val_loss: 0.0604\n",
      "Epoch 942/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1689 - val_loss: 0.0610\n",
      "Epoch 943/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.8592e-04 - val_loss: 0.0616\n",
      "Epoch 944/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.5670e-05 - val_loss: 0.0621\n",
      "Epoch 945/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0322 - val_loss: 0.0625\n",
      "Epoch 946/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 0.0628\n",
      "Epoch 947/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3624 - val_loss: 0.0635\n",
      "Epoch 948/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.2010e-04 - val_loss: 0.0642\n",
      "Epoch 949/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1677 - val_loss: 0.0651\n",
      "Epoch 950/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1345 - val_loss: 0.0660\n",
      "Epoch 951/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0016 - val_loss: 0.0668\n",
      "Epoch 952/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.1100e-04 - val_loss: 0.0675\n",
      "Epoch 953/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7791e-05 - val_loss: 0.0682\n",
      "Epoch 954/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3291 - val_loss: 0.0691\n",
      "Epoch 955/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3346 - val_loss: 0.0692\n",
      "Epoch 956/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.0250e-04 - val_loss: 0.0694\n",
      "Epoch 957/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - val_loss: 0.0695\n",
      "Epoch 958/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0604 - val_loss: 0.0694\n",
      "Epoch 959/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 0.0692\n",
      "Epoch 960/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.0689\n",
      "Epoch 961/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1267 - val_loss: 0.0689\n",
      "Epoch 962/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1256 - val_loss: 0.0692\n",
      "Epoch 963/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4698e-05 - val_loss: 0.0694\n",
      "Epoch 964/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7840e-04 - val_loss: 0.0696\n",
      "Epoch 965/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - val_loss: 0.0698\n",
      "Epoch 966/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - val_loss: 0.0701\n",
      "Epoch 967/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0968 - val_loss: 0.0701\n",
      "Epoch 968/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.4360e-04 - val_loss: 0.0702\n",
      "Epoch 969/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0365 - val_loss: 0.0703\n",
      "Epoch 970/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1183 - val_loss: 0.0707\n",
      "Epoch 971/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.0963e-07 - val_loss: 0.0710\n",
      "Epoch 972/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0042 - val_loss: 0.0712\n",
      "Epoch 973/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0416 - val_loss: 0.0716\n",
      "Epoch 974/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.4383e-04 - val_loss: 0.0721\n",
      "Epoch 975/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2508 - val_loss: 0.0730\n",
      "Epoch 976/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.2148e-04 - val_loss: 0.0739\n",
      "Epoch 977/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0555 - val_loss: 0.0745\n",
      "Epoch 978/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.5959e-04 - val_loss: 0.0750\n",
      "Epoch 979/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1233e-04 - val_loss: 0.0755\n",
      "Epoch 980/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0156 - val_loss: 0.0762\n",
      "Epoch 981/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6443e-04 - val_loss: 0.0768\n",
      "Epoch 982/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4011 - val_loss: 0.0779\n",
      "Epoch 983/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2482 - val_loss: 0.0796\n",
      "Epoch 984/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.1676e-05 - val_loss: 0.0811\n",
      "Epoch 985/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.9648e-04 - val_loss: 0.0825\n",
      "Epoch 986/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 0.0836\n",
      "Epoch 987/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2220 - val_loss: 0.0854\n",
      "Epoch 988/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - val_loss: 0.0869\n",
      "Epoch 989/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0100 - val_loss: 0.0884\n",
      "Epoch 990/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.0897\n",
      "Epoch 991/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2170 - val_loss: 0.0912\n",
      "Epoch 992/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0059 - val_loss: 0.0926\n",
      "Epoch 993/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0042 - val_loss: 0.0939\n",
      "Epoch 994/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0074 - val_loss: 0.0949\n",
      "Epoch 995/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2203 - val_loss: 0.0963\n",
      "Epoch 996/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1189 - val_loss: 0.0984\n",
      "Epoch 997/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2839e-04 - val_loss: 0.1003\n",
      "Epoch 998/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0506 - val_loss: 0.1024\n",
      "Epoch 999/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2429 - val_loss: 0.1026\n",
      "Epoch 1000/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.4437e-04 - val_loss: 0.1028\n",
      "Epoch 1001/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0200 - val_loss: 0.1031\n",
      "Epoch 1002/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6947 - val_loss: 0.1015\n",
      "Epoch 1003/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0070 - val_loss: 0.1001\n",
      "Epoch 1004/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3196 - val_loss: 0.0997\n",
      "Epoch 1005/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - val_loss: 0.0992\n",
      "Epoch 1006/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - val_loss: 0.0989\n",
      "Epoch 1007/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6768e-04 - val_loss: 0.0987\n",
      "Epoch 1008/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - val_loss: 0.0984\n",
      "Epoch 1009/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4333e-04 - val_loss: 0.0981\n",
      "Epoch 1010/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.8461e-04 - val_loss: 0.0979\n",
      "Epoch 1011/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3092e-05 - val_loss: 0.0978\n",
      "Epoch 1012/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0069 - val_loss: 0.0975\n",
      "Epoch 1013/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0116 - val_loss: 0.0972\n",
      "Epoch 1014/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3404 - val_loss: 0.0977\n",
      "Epoch 1015/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0667 - val_loss: 0.0981\n",
      "Epoch 1016/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0838 - val_loss: 0.0979\n",
      "Epoch 1017/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.1266e-06 - val_loss: 0.0978\n",
      "Epoch 1018/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.0584e-05 - val_loss: 0.0976\n",
      "Epoch 1019/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0065 - val_loss: 0.0973\n",
      "Epoch 1020/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.8641e-05 - val_loss: 0.0971\n",
      "Epoch 1021/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5882 - val_loss: 0.0956\n",
      "Epoch 1022/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0690 - val_loss: 0.0946\n",
      "Epoch 1023/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0695 - val_loss: 0.0940\n",
      "Epoch 1024/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0897 - val_loss: 0.0937\n",
      "Epoch 1025/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1232 - val_loss: 0.0926\n",
      "Epoch 1026/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0078 - val_loss: 0.0915\n",
      "Epoch 1027/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.0906\n",
      "Epoch 1028/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 0.0898\n",
      "Epoch 1029/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3354 - val_loss: 0.0900\n",
      "Epoch 1030/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - val_loss: 0.0900\n",
      "Epoch 1031/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1889 - val_loss: 0.0907\n",
      "Epoch 1032/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0881 - val_loss: 0.0915\n",
      "Epoch 1033/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0975 - val_loss: 0.0925\n",
      "Epoch 1034/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1281 - val_loss: 0.0931\n",
      "Epoch 1035/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - val_loss: 0.0936\n",
      "Epoch 1036/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1293 - val_loss: 0.0937\n",
      "Epoch 1037/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0777 - val_loss: 0.0941\n",
      "Epoch 1038/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - val_loss: 0.0943\n",
      "Epoch 1039/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0081 - val_loss: 0.0943\n",
      "Epoch 1040/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.0941\n",
      "Epoch 1041/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0915 - val_loss: 0.0934\n",
      "Epoch 1042/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - val_loss: 0.0926\n",
      "Epoch 1043/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0932 - val_loss: 0.0922\n",
      "Epoch 1044/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2114 - val_loss: 0.0921\n",
      "Epoch 1045/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0064 - val_loss: 0.0918\n",
      "Epoch 1046/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0094 - val_loss: 0.0915\n",
      "Epoch 1047/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0621 - val_loss: 0.0911\n",
      "Epoch 1048/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.0907\n",
      "Epoch 1049/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.2453e-04 - val_loss: 0.0904\n",
      "Epoch 1050/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.0902\n",
      "Epoch 1051/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.0338e-04 - val_loss: 0.0901\n",
      "Epoch 1052/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0796 - val_loss: 0.0901\n",
      "Epoch 1053/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 0.0903\n",
      "Epoch 1054/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6952e-04 - val_loss: 0.0904\n",
      "Epoch 1055/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 0.0905\n",
      "Epoch 1056/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5687 - val_loss: 0.0894\n",
      "Epoch 1057/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0704 - val_loss: 0.0888\n",
      "Epoch 1058/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0021 - val_loss: 0.0882\n",
      "Epoch 1059/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 0.0876\n",
      "Epoch 1060/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0213 - val_loss: 0.0871\n",
      "Epoch 1061/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.3221e-04 - val_loss: 0.0868\n",
      "Epoch 1062/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0051 - val_loss: 0.0864\n",
      "Epoch 1063/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - val_loss: 0.0861\n",
      "Epoch 1064/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 0.0858\n",
      "Epoch 1065/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0024 - val_loss: 0.0857\n",
      "Epoch 1066/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0835 - val_loss: 0.0857\n",
      "Epoch 1067/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.7212e-04 - val_loss: 0.0857\n",
      "Epoch 1068/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0080 - val_loss: 0.0858\n",
      "Epoch 1069/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2119 - val_loss: 0.0862\n",
      "Epoch 1070/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 0.0865\n",
      "Epoch 1071/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 0.0867\n",
      "Epoch 1072/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0070 - val_loss: 0.0870\n",
      "Epoch 1073/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - val_loss: 0.0873\n",
      "Epoch 1074/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - val_loss: 0.0876\n",
      "Epoch 1075/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 0.0878\n",
      "Epoch 1076/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0014 - val_loss: 0.0879\n",
      "Epoch 1077/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3604 - val_loss: 0.0867\n",
      "Epoch 1078/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.0939e-05 - val_loss: 0.0855\n",
      "Epoch 1079/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1305 - val_loss: 0.0843\n",
      "Epoch 1080/1300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0049 - val_loss: 0.0833\n",
      "Epoch 1081/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1939 - val_loss: 0.0830\n",
      "Epoch 1082/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.0827\n",
      "Epoch 1083/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3563 - val_loss: 0.0831\n",
      "Epoch 1084/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0118 - val_loss: 0.0835\n",
      "Epoch 1085/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - val_loss: 0.0840\n",
      "Epoch 1086/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - val_loss: 0.0846\n",
      "Epoch 1087/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0718 - val_loss: 0.0847\n",
      "Epoch 1088/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 0.0849\n",
      "Epoch 1089/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 0.0852\n",
      "Epoch 1090/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5570e-04 - val_loss: 0.0855\n",
      "Epoch 1091/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4952 - val_loss: 0.0848\n",
      "Epoch 1092/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0035 - val_loss: 0.0842\n",
      "Epoch 1093/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0013 - val_loss: 0.0837\n",
      "Epoch 1094/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - val_loss: 0.0833\n",
      "Epoch 1095/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.5511e-04 - val_loss: 0.0830\n",
      "Epoch 1096/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4241 - val_loss: 0.0818\n",
      "Epoch 1097/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0101 - val_loss: 0.0806\n",
      "Epoch 1098/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1018 - val_loss: 0.0797\n",
      "Epoch 1099/1300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.3496e-04 - val_loss: 0.0790\n",
      "Epoch 1100/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0056 - val_loss: 0.0783\n",
      "Epoch 1101/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3604 - val_loss: 0.0769\n",
      "Epoch 1102/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.9346e-04 - val_loss: 0.0757\n",
      "Epoch 1103/1300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1257 - val_loss: 0.0750\n",
      "Epoch 1104/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0025 - val_loss: 0.0744\n",
      "Epoch 1105/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0020 - val_loss: 0.0738\n",
      "Epoch 1106/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0377 - val_loss: 0.0733\n",
      "Epoch 1107/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.0597e-04 - val_loss: 0.0729\n",
      "Epoch 1108/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0388 - val_loss: 0.0725\n",
      "Epoch 1109/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0019 - val_loss: 0.0722\n",
      "Epoch 1110/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0017 - val_loss: 0.0718\n",
      "Epoch 1111/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0410 - val_loss: 0.0713\n",
      "Epoch 1112/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0072 - val_loss: 0.0708\n",
      "Epoch 1113/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3049e-04 - val_loss: 0.0703\n",
      "Epoch 1114/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1434 - val_loss: 0.0701\n",
      "Epoch 1115/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 5.9690e-05 - val_loss: 0.0698\n",
      "Epoch 1116/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0036 - val_loss: 0.0696\n",
      "Epoch 1117/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2478 - val_loss: 0.0695\n",
      "Epoch 1118/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0013 - val_loss: 0.0695\n",
      "Epoch 1119/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0056 - val_loss: 0.0695\n",
      "Epoch 1120/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.5309e-04 - val_loss: 0.0695\n",
      "Epoch 1121/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.5781e-05 - val_loss: 0.0695\n",
      "Epoch 1122/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2686 - val_loss: 0.0690\n",
      "Epoch 1123/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 4.4588e-04 - val_loss: 0.0686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1124/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0023 - val_loss: 0.0683\n",
      "Epoch 1125/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1139 - val_loss: 0.0677\n",
      "Epoch 1126/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2497 - val_loss: 0.0667\n",
      "Epoch 1127/1300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.3395e-04 - val_loss: 0.0659\n",
      "Epoch 1128/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0237 - val_loss: 0.0650\n",
      "Epoch 1129/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3333 - val_loss: 0.0648\n",
      "Epoch 1130/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.7474e-04 - val_loss: 0.0647\n",
      "Epoch 1131/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0021 - val_loss: 0.0645\n",
      "Epoch 1132/1300\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0018 - val_loss: 0.0643\n",
      "Epoch 1133/1300\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0023 - val_loss: 0.0641\n",
      "Epoch 1134/1300\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1681 - val_loss: 0.0640\n",
      "Epoch 1135/1300\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1783 - val_loss: 0.0641\n",
      "Epoch 1136/1300\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0033 - val_loss: 0.0642\n",
      "Epoch 1137/1300\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0015 - val_loss: 0.0642\n",
      "Epoch 1138/1300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.4963e-04 - val_loss: 0.0643\n",
      "Epoch 1139/1300\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1763 - val_loss: 0.0645\n",
      "Epoch 1140/1300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0073 - val_loss: 0.0648\n",
      "Epoch 1141/1300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.4654e-04 - val_loss: 0.0649\n",
      "Epoch 1142/1300\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0026 - val_loss: 0.0652\n",
      "Epoch 1143/1300\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 3.4975e-04 - val_loss: 0.0654\n",
      "Epoch 1144/1300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1100 - val_loss: 0.0653\n",
      "Epoch 1145/1300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0232 - val_loss: 0.0650\n",
      "Epoch 1146/1300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0778 - val_loss: 0.0649\n",
      "Epoch 1147/1300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0042 - val_loss: 0.0649\n",
      "Epoch 1148/1300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0019 - val_loss: 0.0650\n",
      "Epoch 1149/1300\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.3544 - val_loss: 0.0653\n",
      "Epoch 1150/1300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0791 - val_loss: 0.0655\n",
      "Epoch 1151/1300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0017 - val_loss: 0.0657\n",
      "Epoch 1152/1300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0014 - val_loss: 0.0658\n",
      "Epoch 1153/1300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0018 - val_loss: 0.0660\n",
      "Epoch 1154/1300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0072 - val_loss: 0.0663\n",
      "Epoch 1155/1300\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0027 - val_loss: 0.0666\n",
      "Epoch 1156/1300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0085 - val_loss: 0.0670\n",
      "Epoch 1157/1300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 7.5671e-05 - val_loss: 0.0673\n",
      "Epoch 1158/1300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 3.0274e-04 - val_loss: 0.0677\n",
      "Epoch 1159/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3722 - val_loss: 0.0684\n",
      "Epoch 1160/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1473 - val_loss: 0.0692\n",
      "Epoch 1161/1300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 8.8095e-04 - val_loss: 0.0701\n",
      "Epoch 1162/1300\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2401 - val_loss: 0.0710\n",
      "Epoch 1163/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - val_loss: 0.0718\n",
      "Epoch 1164/1300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3418 - val_loss: 0.0729\n",
      "Epoch 1165/1300\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.7526e-04 - val_loss: 0.0740\n",
      "Epoch 1166/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1224 - val_loss: 0.0753\n",
      "Epoch 1167/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0487 - val_loss: 0.0763\n",
      "Epoch 1168/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1283 - val_loss: 0.0776\n",
      "Epoch 1169/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 8.8293e-04 - val_loss: 0.0787\n",
      "Epoch 1170/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0027 - val_loss: 0.0798\n",
      "Epoch 1171/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0081 - val_loss: 0.0807\n",
      "Epoch 1172/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.1864e-04 - val_loss: 0.0815\n",
      "Epoch 1173/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 9.8644e-04 - val_loss: 0.0823\n",
      "Epoch 1174/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2747 - val_loss: 0.0834\n",
      "Epoch 1175/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0253 - val_loss: 0.0844\n",
      "Epoch 1176/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2583 - val_loss: 0.0860\n",
      "Epoch 1177/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0052 - val_loss: 0.0873\n",
      "Epoch 1178/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0052 - val_loss: 0.0884\n",
      "Epoch 1179/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0893\n",
      "Epoch 1180/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 7.5949e-06 - val_loss: 0.0901\n",
      "Epoch 1181/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2215 - val_loss: 0.0915\n",
      "Epoch 1182/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0186 - val_loss: 0.0929\n",
      "Epoch 1183/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0039 - val_loss: 0.0940\n",
      "Epoch 1184/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0011 - val_loss: 0.0951\n",
      "Epoch 1185/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0793 - val_loss: 0.0963\n",
      "Epoch 1186/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0973\n",
      "Epoch 1187/1300\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 7.5083e-04 - val_loss: 0.0982\n",
      "Epoch 1188/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0729 - val_loss: 0.0992\n",
      "Epoch 1189/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.9074e-04 - val_loss: 0.1002\n",
      "Epoch 1190/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0028 - val_loss: 0.1012\n",
      "Epoch 1191/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0118 - val_loss: 0.1022\n",
      "Epoch 1192/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0588 - val_loss: 0.1035\n",
      "Epoch 1193/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0156 - val_loss: 0.1047\n",
      "Epoch 1194/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0414 - val_loss: 0.1061\n",
      "Epoch 1195/1300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.2763e-05 - val_loss: 0.1074\n",
      "Epoch 1196/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0011 - val_loss: 0.1085\n",
      "Epoch 1197/1300\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0059 - val_loss: 0.1094\n",
      "Epoch 1198/1300\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0891 - val_loss: 0.1110\n",
      "Epoch 1199/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0781 - val_loss: 0.1119\n",
      "Epoch 1200/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.2917e-04 - val_loss: 0.1128\n",
      "Epoch 1201/1300\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0019 - val_loss: 0.1136\n",
      "Epoch 1202/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6234 - val_loss: 0.1113\n",
      "Epoch 1203/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 6.2896e-05 - val_loss: 0.1094\n",
      "Epoch 1204/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0221 - val_loss: 0.1076\n",
      "Epoch 1205/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0051 - val_loss: 0.1061\n",
      "Epoch 1206/1300\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.5399e-04 - val_loss: 0.1048\n",
      "Epoch 1207/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0052 - val_loss: 0.1037\n",
      "Epoch 1208/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0141 - val_loss: 0.1028\n",
      "Epoch 1209/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0658 - val_loss: 0.1017\n",
      "Epoch 1210/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.2137e-05 - val_loss: 0.1007\n",
      "Epoch 1211/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0067 - val_loss: 0.1000\n",
      "Epoch 1212/1300\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0026 - val_loss: 0.0993\n",
      "Epoch 1213/1300\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 9.0517e-06 - val_loss: 0.0988\n",
      "Epoch 1214/1300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0585 - val_loss: 0.0985\n",
      "Epoch 1215/1300\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0099 - val_loss: 0.0983\n",
      "Epoch 1216/1300\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 6.0820e-04 - val_loss: 0.0981\n",
      "Epoch 1217/1300\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.1678 - val_loss: 0.0976\n",
      "Epoch 1218/1300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0021 - val_loss: 0.0972\n",
      "Epoch 1219/1300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0018 - val_loss: 0.0969\n",
      "Epoch 1220/1300\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0016 - val_loss: 0.0966\n",
      "Epoch 1221/1300\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0089 - val_loss: 0.0965\n",
      "Epoch 1222/1300\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 5.7560e-04 - val_loss: 0.0965\n",
      "Epoch 1223/1300\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0409 - val_loss: 0.0968\n",
      "Epoch 1224/1300\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.5388e-04 - val_loss: 0.0970\n",
      "Epoch 1225/1300\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0023 - val_loss: 0.0972\n",
      "Epoch 1226/1300\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0030 - val_loss: 0.0975\n",
      "Epoch 1227/1300\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.4723e-06 - val_loss: 0.0978\n",
      "Epoch 1228/1300\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1745 - val_loss: 0.0987\n",
      "Epoch 1229/1300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.5946e-05 - val_loss: 0.0996\n",
      "Epoch 1230/1300\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0786 - val_loss: 0.0999\n",
      "Epoch 1231/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3238 - val_loss: 0.1010\n",
      "Epoch 1232/1300\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2030 - val_loss: 0.1024\n",
      "Epoch 1233/1300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0513 - val_loss: 0.1041\n",
      "Epoch 1234/1300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.6977e-04 - val_loss: 0.1055\n",
      "Epoch 1235/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1776 - val_loss: 0.1071\n",
      "Epoch 1236/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0060 - val_loss: 0.1085\n",
      "Epoch 1237/1300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0102 - val_loss: 0.1094\n",
      "Epoch 1238/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8923e-05 - val_loss: 0.1104\n",
      "Epoch 1239/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5744e-04 - val_loss: 0.1111\n",
      "Epoch 1240/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0210 - val_loss: 0.1117\n",
      "Epoch 1241/1300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1801 - val_loss: 0.1128\n",
      "Epoch 1242/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1774 - val_loss: 0.1143\n",
      "Epoch 1243/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0483 - val_loss: 0.1160\n",
      "Epoch 1244/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.1173\n",
      "Epoch 1245/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1185\n",
      "Epoch 1246/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8012e-04 - val_loss: 0.1196\n",
      "Epoch 1247/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7846e-04 - val_loss: 0.1206\n",
      "Epoch 1248/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - val_loss: 0.1215\n",
      "Epoch 1249/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7230e-05 - val_loss: 0.1222\n",
      "Epoch 1250/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.9191e-05 - val_loss: 0.1229\n",
      "Epoch 1251/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.1208e-05 - val_loss: 0.1236\n",
      "Epoch 1252/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0213 - val_loss: 0.1245\n",
      "Epoch 1253/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - val_loss: 0.1253\n",
      "Epoch 1254/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0142 - val_loss: 0.1259\n",
      "Epoch 1255/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1452 - val_loss: 0.1270\n",
      "Epoch 1256/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.1281\n",
      "Epoch 1257/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2215 - val_loss: 0.1284\n",
      "Epoch 1258/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0055 - val_loss: 0.1285\n",
      "Epoch 1259/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0373 - val_loss: 0.1290\n",
      "Epoch 1260/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - val_loss: 0.1294\n",
      "Epoch 1261/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0796 - val_loss: 0.1306\n",
      "Epoch 1262/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.1316\n",
      "Epoch 1263/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0743 - val_loss: 0.1332\n",
      "Epoch 1264/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0347 - val_loss: 0.1354\n",
      "Epoch 1265/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - val_loss: 0.1372\n",
      "Epoch 1266/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2917 - val_loss: 0.1400\n",
      "Epoch 1267/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2864 - val_loss: 0.1435\n",
      "Epoch 1268/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0098 - val_loss: 0.1465\n",
      "Epoch 1269/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9486 - val_loss: 0.1442\n",
      "Epoch 1270/1300\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0251 - val_loss: 0.1424\n",
      "Epoch 1271/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8692 - val_loss: 0.1369\n",
      "Epoch 1272/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1326e-04 - val_loss: 0.1323\n",
      "Epoch 1273/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0010 - val_loss: 0.1283\n",
      "Epoch 1274/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0180 - val_loss: 0.1253\n",
      "Epoch 1275/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - val_loss: 0.1226\n",
      "Epoch 1276/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0112 - val_loss: 0.1200\n",
      "Epoch 1277/1300\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0217 - val_loss: 0.1174\n",
      "Epoch 1278/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1366 - val_loss: 0.1159\n",
      "Epoch 1279/1300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6276e-04 - val_loss: 0.1145\n",
      "Epoch 1280/1300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6632 - val_loss: 0.1119\n",
      "Epoch 1281/1300\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0021 - val_loss: 0.1098\n",
      "Epoch 1282/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0486 - val_loss: 0.1082\n",
      "Epoch 1283/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0135 - val_loss: 0.1065\n",
      "Epoch 1284/1300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0114 - val_loss: 0.1047\n",
      "Epoch 1285/1300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0125 - val_loss: 0.1029\n",
      "Epoch 1286/1300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5425 - val_loss: 0.0999\n",
      "Epoch 1287/1300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.3304e-05 - val_loss: 0.0974\n",
      "Epoch 1288/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1849 - val_loss: 0.0955\n",
      "Epoch 1289/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0537e-04 - val_loss: 0.0937\n",
      "Epoch 1290/1300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0028 - val_loss: 0.0921\n",
      "Epoch 1291/1300\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.2855e-05 - val_loss: 0.0906\n",
      "Epoch 1292/1300\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0011 - val_loss: 0.0894\n",
      "Epoch 1293/1300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 2.2121e-05 - val_loss: 0.0884\n",
      "Epoch 1294/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0231 - val_loss: 0.0875\n",
      "Epoch 1295/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1286 - val_loss: 0.0866\n",
      "Epoch 1296/1300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0210 - val_loss: 0.0858\n",
      "Epoch 1297/1300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0019 - val_loss: 0.0852\n",
      "Epoch 1298/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0291e-04 - val_loss: 0.0846\n",
      "Epoch 1299/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2755 - val_loss: 0.0846\n",
      "Epoch 1300/1300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 8.8911e-05 - val_loss: 0.0846\n"
     ]
    }
   ],
   "source": [
    "LSTM_model_2 = Sequential()\n",
    "LSTM_model_2.add(LSTM(256,activation=\"relu\", input_shape=(look_back,1),return_sequences=True))\n",
    "LSTM_model_2.add(LSTM(126,activation=\"relu\",return_sequences=True))\n",
    "LSTM_model_2.add(LSTM(32,activation=\"relu\",return_sequences=False))\n",
    "LSTM_model_2.add(Dense(1))\n",
    "LSTM_model_2.compile(optimizer = keras.optimizers.Adam(learning_rate=0.0001), loss = 'mean_squared_error')\n",
    "history = LSTM_model_2.fit(train_genertor, validation_data=test_genertor_31, steps_per_epoch = 1,epochs = 1300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a30f11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.4273939   1.3313589   1.0803893   1.0265998   0.8659614   0.57155204\n",
      "  0.3067733  -0.1924723  -0.21778363 -0.52329373 -0.6194306  -0.66516656\n",
      " -0.678479   -0.68862325 -0.65309066 -0.59758127 -0.53229934 -0.44523567\n",
      " -0.3699688  -0.33083573 -0.3065249  -0.2584786  -0.24842346 -0.39281905\n",
      " -0.4972879  -0.50315547 -0.5097003  -0.4872502  -0.41363454 -0.39544722\n",
      " -0.4223214  -0.3564301  -0.18933854  0.10412344  0.26981437  0.4759003\n",
      "  0.6116396   1.0974541 ]\n"
     ]
    }
   ],
   "source": [
    "y_predict_training = LSTM_model_2.predict(train_genertor)\n",
    "y_predict_39 = LSTM_model_2.predict(test_genertor_39)\n",
    "y_predict_39 = y_predict_39.reshape((-1))\n",
    "print(y_predict_39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c59775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_sample_1 = y_predict_39[0:1]\n",
    "y_predict_sample_2 = y_predict_39[1:2]\n",
    "y_predict_sample_3 = y_predict_39[2:3]\n",
    "y_predict_sample_4 = y_predict_39[3:4]\n",
    "y_predict_sample_5 = y_predict_39[4:5]\n",
    "y_predict_sample_6 = y_predict_39[5:6]\n",
    "y_predict_sample_7 = y_predict_39[6:7]\n",
    "y_predict_sample_8 = y_predict_39[7:8]\n",
    "y_predict_sample_9 = y_predict_39[8:9]\n",
    "y_predict_sample_10 = y_predict_39[9:10]\n",
    "y_predict_sample_11 = y_predict_39[10:11]\n",
    "y_predict_sample_12 = y_predict_39[11:12]\n",
    "y_predict_sample_13 = y_predict_39[12:13]\n",
    "y_predict_sample_14 = y_predict_39[13:14]\n",
    "y_predict_sample_15 = y_predict_39[14:15]\n",
    "y_predict_sample_16 = y_predict_39[15:16]\n",
    "y_predict_sample_17 = y_predict_39[16:17]\n",
    "y_predict_sample_18 = y_predict_39[17:18]\n",
    "y_predict_sample_19 = y_predict_39[18:19]\n",
    "y_predict_sample_20 = y_predict_39[19:20]\n",
    "y_predict_sample_21 = y_predict_39[20:21]\n",
    "y_predict_sample_22 = y_predict_39[21:22]\n",
    "y_predict_sample_23 = y_predict_39[22:23]\n",
    "y_predict_sample_24 = y_predict_39[23:24]\n",
    "y_predict_sample_25 = y_predict_39[24:25]\n",
    "y_predict_sample_26 = y_predict_39[25:26]\n",
    "y_predict_sample_27 = y_predict_39[26:27]\n",
    "y_predict_sample_28 = y_predict_39[27:28]\n",
    "y_predict_sample_29 = y_predict_39[28:29]\n",
    "y_predict_sample_30 = y_predict_39[29:30]\n",
    "y_predict_sample_31 = y_predict_39[30:31]\n",
    "y_predict_sample_32 = y_predict_39[31:32]\n",
    "y_predict_sample_33 = y_predict_39[32:33]\n",
    "y_predict_sample_34 = y_predict_39[33:34]\n",
    "y_predict_sample_35 = y_predict_39[34:35]\n",
    "y_predict_sample_36 = y_predict_39[35:36]\n",
    "y_predict_sample_37 = y_predict_39[36:37]\n",
    "y_predict_sample_38 = y_predict_39[37:38]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3f46b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score stable week prediction :  -0.7609139593861469\n",
      "r2 score volatile week prediction:  0.3542473670091716\n",
      "r2 score 38 week prediction:  0.9564708037770766\n",
      "0.9846563741232436\n"
     ]
    }
   ],
   "source": [
    "r2scoremodel_39=r2_score(testing_data_39[:-2], y_predict_39)\n",
    "print(\"r2 score 38 week prediction: \",r2scoremodel_39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61115819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 38 week prediction: 0.0188\n",
      "RMSE stable weeks: 0.0055\n",
      "RMSE volatile weeks: 0.0092\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE 38 week prediction: {0:0.4f}\".format(mean_squared_error(testing_data_39[:-2], y_predict_39)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37c7dd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 38 week prediction: 0.1141\n",
      "MAE stable week: 0.0649\n",
      "MAE volatile week: 0.0925\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE 38 week prediction: {0:0.4f}\".format(mean_absolute_error(testing_data_39[:-2], y_predict_39)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "148c8c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 38 samples\n",
      "0.0419, \n",
      " 0.1319,\n",
      "0.1062,\n",
      "0.1198,\n",
      "0.1905,\n",
      " 0.0555,\n",
      "0.1081,\n",
      "0.1726,\n",
      "0.0854,\n",
      " 0.0398,\n",
      "0.0291,\n",
      "0.0312,\n",
      "0.0242,\n",
      " 0.0337,\n",
      "0.0488,\n",
      "0.0613,\n",
      "0.0824,\n",
      " 0.1060,\n",
      "0.1143,\n",
      "0.1178,\n",
      "0.1297,\n",
      " 0.1473,\n",
      "0.1169,\n",
      "0.0670,\n",
      "0.0708,\n",
      " 0.0689,\n",
      "0.0675,\n",
      "0.0938,\n",
      "0.1052,\n",
      " 0.0837,\n",
      "0.1039,\n",
      "0.1278,\n",
      "0.2244,\n",
      " 0.2513,\n",
      "0.3127,\n",
      "0.2506,\n",
      "0.0608,\n",
      "0.3525,\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE 38 samples\")\n",
    "print(\"{0:0.4f}, \".format(mean_absolute_error(Y_test_1_sample, y_predict_sample_1)))\n",
    "print(\" {0:0.4f},\".format(mean_absolute_error(Y_test_2_sample, y_predict_sample_2)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_3_sample, y_predict_sample_3)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_4_sample, y_predict_sample_4)))\n",
    "\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_5_sample, y_predict_sample_5)))\n",
    "print(\" {0:0.4f},\".format(mean_absolute_error(Y_test_6_sample, y_predict_sample_6)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_7_sample, y_predict_sample_7)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_8_sample, y_predict_sample_8)))\n",
    "\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_9_sample, y_predict_sample_9)))\n",
    "print(\" {0:0.4f},\".format(mean_absolute_error(Y_test_10_sample, y_predict_sample_10)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_11_sample, y_predict_sample_11)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_12_sample, y_predict_sample_12)))\n",
    "\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_13_sample, y_predict_sample_13)))\n",
    "print(\" {0:0.4f},\".format(mean_absolute_error(Y_test_14_sample, y_predict_sample_14)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_15_sample, y_predict_sample_15)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_16_sample, y_predict_sample_16)))\n",
    "\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_17_sample, y_predict_sample_17)))\n",
    "print(\" {0:0.4f},\".format(mean_absolute_error(Y_test_18_sample, y_predict_sample_18)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_19_sample, y_predict_sample_19)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_20_sample, y_predict_sample_20)))\n",
    "\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_21_sample, y_predict_sample_21)))\n",
    "print(\" {0:0.4f},\".format(mean_absolute_error(Y_test_22_sample, y_predict_sample_22)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_23_sample, y_predict_sample_23)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_24_sample, y_predict_sample_24)))\n",
    "\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_25_sample, y_predict_sample_25)))\n",
    "print(\" {0:0.4f},\".format(mean_absolute_error(Y_test_26_sample, y_predict_sample_26)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_27_sample, y_predict_sample_27)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_28_sample, y_predict_sample_28)))\n",
    "\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_29_sample, y_predict_sample_29)))\n",
    "print(\" {0:0.4f},\".format(mean_absolute_error(Y_test_30_sample, y_predict_sample_30)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_31_sample, y_predict_sample_31)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_32_sample, y_predict_sample_32)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_33_sample, y_predict_sample_33)))\n",
    "\n",
    "print(\" {0:0.4f},\".format(mean_absolute_error(Y_test_34_sample, y_predict_sample_34)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_35_sample, y_predict_sample_35)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_36_sample, y_predict_sample_36)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_37_sample, y_predict_sample_37)))\n",
    "print(\"{0:0.4f},\".format(mean_absolute_error(Y_test_38_sample, y_predict_sample_38)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c168c11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 2, 256)            264192    \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 2, 126)            193032    \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 32)                20352     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 477,609\n",
      "Trainable params: 477,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd26a260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 6))\n",
    "# creating the bar plot\n",
    "ax.plot(testing_data_39[:-2]*Y_sd_2+Y_mu_2, label='Actual', color ='blue')\n",
    "ax.plot(y_predict_39*Y_sd_2+Y_mu_2,label='Predicted LSTM', color ='orange')\n",
    "ax.set_xlabel(\"Week\")\n",
    "ax.set_ylabel(\"No. of infections\")\n",
    "ax.set_title(\"38 week Predicted Vs. Actual\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8d738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
